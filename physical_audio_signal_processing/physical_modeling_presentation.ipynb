{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Physical Models of Musical Instruments\n",
    "\n",
    "* Pt 1: Guitar\n",
    "* Pt 2: Piano\n",
    "* Pt 3: Woodwind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 1: Guitar String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('Qr_rxqwc1jE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../introduction_to_digital_filters/')\n",
    "from PlotUtils import plot_frequency_response\n",
    "from ipython_animation import create_animation, DEFAULT_FPS\n",
    "from DelayLine import DelayLine\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import freqz\n",
    "from IPython.display import Audio\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 4)\n",
    "_ = np.seterr(divide='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from DelayLine import DelayLine\n",
    "\n",
    "def bandlimited_triangle_pluck(length):\n",
    "    pluck = np.zeros(length)\n",
    "    pluck[0:length // 4] = np.linspace(0, 1, length // 4)\n",
    "    pluck[length // 4:length] = np.linspace(1, 0, length - length // 4)\n",
    "    return np.fft.irfft(np.fft.rfft(pluck, length)[:length//3], length) # remove some HF components\n",
    "\n",
    "class Waveguide:\n",
    "    def __init__(self,\n",
    "                 length_samples=21,\n",
    "                 pickup_sample=4,\n",
    "                 wave_variable_label='y'):\n",
    "        self.length_samples = length_samples\n",
    "        self.pickup_sample = pickup_sample\n",
    "        self.d_l = DelayLine(length_samples)\n",
    "        self.d_r = DelayLine(length_samples)\n",
    "        self.set_initial_shape(bandlimited_triangle_pluck(length_samples))\n",
    "        self.bridge_reflection_y_0 = 0 # memory for single pole lowpass filter at bridge\n",
    "        self.wave_variable_label = wave_variable_label\n",
    "\n",
    "    def set_initial_shape(self, y_init):\n",
    "        y_l = y_init / 2\n",
    "        y_r = y_init / 2\n",
    "        self.d_r.tick_all(y_r[::-1])\n",
    "        self.d_l.tick_all(y_l)\n",
    "\n",
    "    def tick(self):\n",
    "        r = self.d_r.get_tap(1) # least recent sample from rightgoing wave component - traveling into nut\n",
    "        l = self.d_l.get_tap(1) # least recent sample from leftgoing wave component - traveling into bridge\n",
    "        self.d_l.tick(-r) # negative reflection at right rigid termination (nut)\n",
    "        self.d_r.tick(-l) # negative reflection at left termination (bridge)\n",
    "        \n",
    "        return self.tap_pickup()\n",
    "\n",
    "    def tap_pickup(self, pickup_sample=None):\n",
    "        pickup_sample = pickup_sample if pickup_sample is not None else self.pickup_sample\n",
    "        return self.d_l.get_tap(pickup_sample) + self.d_r.get_tap(self.length_samples - pickup_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def animate_waveguide(waveguide, num_frames=None, fps=10, ticks_per_frame=1):\n",
    "    L = waveguide.length_samples\n",
    "    wv_label = waveguide.wave_variable_label\n",
    "    L_indices = np.arange(L)\n",
    "    d_l = waveguide.d_l\n",
    "    d_r = waveguide.d_r\n",
    "    num_frames = num_frames or (L - 1) * 2\n",
    "\n",
    "    fig, (y_plot, y_r_plot, y_l_plot, pickup_plot) = plt.subplots(4, 1, figsize=(14, 4 * 3))\n",
    "\n",
    "    y_r_ax, = y_r_plot.plot(d_r.get_all()[::-1], label='${}_r$'.format(wv_label),\n",
    "                            linestyle='--', c='b', alpha=0.7, linewidth=2)\n",
    "    y_l_ax, = y_l_plot.plot(d_l.get_all(), label='${}_l$'.format(wv_label),\n",
    "                            linestyle='--', c='b', alpha=0.7, linewidth=2)\n",
    "    y_ax, = y_plot.plot(d_r.get_all()[::-1] + d_l.get_all(), label='${0}_l + {0}_r$'.format(wv_label),\n",
    "                        linewidth=3, c='b')\n",
    "\n",
    "    y_plot.set_title('${0}(t,x) = {0}_r(t,x) + {0}_l(t,x)$'.format(wv_label), size=16)\n",
    "    y_r_plot.set_title('${}_r(t,x)$'.format(wv_label), size=16)\n",
    "    y_l_plot.set_title('${}_l(t,x)$'.format(wv_label), size=16)\n",
    "\n",
    "    for plot in [y_r_plot, y_l_plot]:\n",
    "        plot.axvline(waveguide.pickup_sample, label='Pickup $x$', linewidth=3, c='black')\n",
    "    pickup_data = np.zeros(num_frames)\n",
    "    pickup_data[0] = waveguide.tap_pickup(waveguide.pickup_sample)\n",
    "    pickup_ax, = pickup_plot.plot(pickup_data, c='black')\n",
    "    pickup_plot.set_xlim(0, num_frames - 1)\n",
    "    pickup_plot.set_ylim(-1.2, 1.2)\n",
    "    pickup_plot.grid(True)\n",
    "    pickup_plot.set_title('Signal from pickup at $x={}$'.format(waveguide.pickup_sample), size=16)\n",
    "    pickup_plot.set_xlabel('$t$ (samples) $\\\\longrightarrow$')\n",
    "\n",
    "    for plot in [y_plot, y_r_plot, y_l_plot]:\n",
    "        plot.legend()\n",
    "        plot.grid(True)\n",
    "        plot.set_ylabel('$y$')\n",
    "        plot.set_ylim(-1.2, 1.2)\n",
    "        plot.set_xlim(0, L - 1)\n",
    "        plot.set_xticks(L_indices)\n",
    "\n",
    "    y_plot.set_xlabel('$x$')\n",
    "    for plot in [y_r_plot, y_l_plot]:\n",
    "        plot.set_xlabel('Delay Line Sample Index')\n",
    "\n",
    "    y_r_plot.set_xticklabels(L_indices[::-1])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    def animate(frame):\n",
    "        if frame < 1:\n",
    "            return\n",
    "\n",
    "        for _ in range(ticks_per_frame):\n",
    "            waveguide.tick()\n",
    "\n",
    "        y_r_x = np.roll(L_indices, -d_l.read_sample)[::-1]\n",
    "        y_r = d_r.get_all()[y_r_x]\n",
    "        y_r_ax.set_ydata(y_r)\n",
    "        y_r_plot.set_xticklabels(y_r_x)\n",
    "\n",
    "        y_l_x = np.roll(L_indices, -d_l.read_sample)\n",
    "        y_l = d_l.get_all()[y_l_x]\n",
    "        y_l_ax.set_ydata(y_l)\n",
    "        y_l_plot.set_xticklabels(y_l_x)\n",
    "\n",
    "        y_ax.set_ydata(y_r + y_l)\n",
    "\n",
    "        pickup_data[frame] = waveguide.tap_pickup()\n",
    "        pickup_ax.set_ydata(pickup_data)\n",
    "\n",
    "    return create_animation(fig, plt, animate, frames=num_frames, frames_per_second=fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Digital waveguide models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "waveguide = Waveguide()\n",
    "animate_waveguide(waveguide, num_frames=waveguide.length_samples*4, fps=20, ticks_per_frame=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "sample_rate = fs = 44100\n",
    "a_hz = 220\n",
    "# Because of the finite sampling of the \"string\", with no interpolating delay line,\n",
    "# this may not actually be 220Hz.\n",
    "a_samples = int(fs / a_hz)\n",
    "\n",
    "waveguide = Waveguide(length_samples=a_samples, pickup_sample=a_samples // 7)\n",
    "waveguide_out = [waveguide.tick() for i in range(fs * 4)]\n",
    "# get rid of harsh begin/end\n",
    "fade_samples = fs//4\n",
    "fade_ramp = np.linspace(0.0, 1.0, fade_samples)\n",
    "waveguide_out[:fade_samples] *= fade_ramp\n",
    "waveguide_out[-fade_samples:] *= fade_ramp[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Audio(waveguide_out, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The above animation shows the travelling-wave decomposition of string vibrations from an initial displacement. We're using displacement as the wave variable, but velocity and force waves move through the string in the same way. Displacement is chosen because:\n",
    "* It's visually intuitive (looks like a real string)\n",
    "* We can extract audio without additional integration\n",
    "* We can easily implement collision detections\n",
    "\n",
    "This first example uses a simple one-pole lowpass filter as a \"yielding bridge\" model (left side). We model the nut (right side) as a rigid termination that simply inverts the right-traveling wave. The energy that's lost at the yielding bridge is _transferred_ to the guitar body (or piano soundboard, etc.). That is, the energy that isn't reflected is transmitted. We don't model that here, but instead \"tap\" into the string directly by summing the two travelling components to get the physical displacement of the string at a specified point along its length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A yielding \"bridge\" termination\n",
    "\n",
    "![](https://static.gibson.com/product-images/Acoustic/ACCSVU796/Antique%20Cherry/front-banner-1600_900.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from Filters import OnePoleFilter\n",
    "\n",
    "class WaveguideWithYieldingBridge(Waveguide):\n",
    "    def __init__(self,\n",
    "                 length_samples=21,\n",
    "                 pickup_sample=4,\n",
    "                 bridge_filter=None,\n",
    "                 wave_variable_label='y'):\n",
    "        super(WaveguideWithYieldingBridge, self).__init__(length_samples, pickup_sample, wave_variable_label)\n",
    "        self.bridge_filter = bridge_filter or OnePoleFilter()\n",
    "\n",
    "    def tick(self):\n",
    "        r = self.d_r.get_tap(1) # least recent sample from rightgoing wave component - traveling into nut\n",
    "        l = self.d_l.get_tap(1) # least recent sample from leftgoing wave component - traveling into bridge\n",
    "        self.d_l.tick(-r) # negative reflection at right rigid termination (nut)\n",
    "        self.d_r.tick(-self.bridge_filter.tick(l)) # negative, yielding reflection at left termination (bridge)\n",
    "\n",
    "        return self.tap_pickup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A yielding \"bridge\" termination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "waveguide = WaveguideWithYieldingBridge()\n",
    "animate_waveguide(waveguide, num_frames=waveguide.length_samples*8, fps=20, ticks_per_frame=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "waveguide = WaveguideWithYieldingBridge(length_samples=a_samples, pickup_sample=a_samples // 7)\n",
    "waveguide_out = [waveguide.tick() for i in range(fs * 7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Audio(waveguide_out, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice that the low frequencies ring out for a very long time. This is because our simple bridge reflectance filter doesn't attenuate the lowest frequencies at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A small improvement in realism would be to slightly damp even the lowest frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "slightly_damped_bridge_filter = OnePoleFilter(0.498, 0.498)\n",
    "waveguide = WaveguideWithYieldingBridge(length_samples=a_samples,\n",
    "                                        pickup_sample=a_samples // 7,\n",
    "                                        bridge_filter=slightly_damped_bridge_filter)\n",
    "waveguide_out = [waveguide.tick() for i in range(fs * 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Audio(waveguide_out, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# String Excitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Where we're headed here is modelling striking or plucking strings with things like hammers and picks (plectra). We'll look at affixed masses, struck strings and plucked strings. Along the way, we'll visualize and listen to the resulting sound with each addition. By the end, we'll end up with decently realistic-sounding models that are very computationally efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "class PointMassReflectionFilter():\n",
    "    def __init__(self, mass=1.0):\n",
    "        # Treat string impedance * sampling interval as a constant for now.\n",
    "        # We can vary the behavior we care about by only changing the mass.\n",
    "        RT = 1.0\n",
    "        denominator = (1 + RT / mass)\n",
    "        denominator = max(denominator, 1e-10) # prevent divide-by-zero\n",
    "        self.g = 1 / denominator\n",
    "        self.p = (1 - RT / mass) / denominator\n",
    "        self.p = min(self.p, 1 - 1e-8) # avoid pole right on the unit circle\n",
    "        self.z_1 = 0.0\n",
    "    \n",
    "    def tick(self, in_sample):\n",
    "        new_z_1 = self.g * in_sample + self.p * self.z_1\n",
    "        out_sample = new_z_1 - self.z_1\n",
    "        self.z_1 = new_z_1\n",
    "        return out_sample\n",
    "\n",
    "    def reset(self):\n",
    "        self.z_1 = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from enum import Enum \n",
    "\n",
    "# Explored later\n",
    "class DampedSpringReflectionFilter():\n",
    "    def __init__(self, k=1.0, damping=1.0):\n",
    "        # Treat string impedance and sampling interval as constants for now.\n",
    "        # We can vary the behavior we care about by only changing k and Âµ (damping)\n",
    "        T = 1.0\n",
    "        R = 1.0\n",
    "        self.p = (1 - k * T / (2 * (damping + 2 * R))) / (1 + k * T / (2 * (damping + 2 * R)))\n",
    "        self.zero = (1 - k * T / (2 * damping)) / (1 + k * T / (2 * damping))\n",
    "        self.g = (1 - self.p) / (1 - self.zero)\n",
    "        self.z_1 = 0.0\n",
    "    \n",
    "    def tick(self, in_sample):\n",
    "        new_z_1 = self.g * in_sample + self.p * self.z_1\n",
    "        out_sample = new_z_1 - self.zero * self.z_1\n",
    "        self.z_1 = new_z_1\n",
    "        return out_sample\n",
    "\n",
    "    def reset(self):\n",
    "        self.z_1 = 0.0\n",
    "\n",
    "class WaveguideWithExcitation(Waveguide):\n",
    "    ExcitationType = Enum('ExcitationType', 'affixed hammer plectrum pluck')\n",
    "\n",
    "    def __init__(self,\n",
    "                 length_samples=42,\n",
    "                 pickup_sample=42//4,\n",
    "                 excitation_sample=42//2,\n",
    "                 tension=0.04,\n",
    "                 excitation_mass=1.0,\n",
    "                 spring_k=None,\n",
    "                 spring_damping=None, # If both k & damping are provided, then a spring filter is used.\n",
    "                 excitation_type=ExcitationType.hammer,\n",
    "                 bridge_filter=None,\n",
    "                 wave_variable_label='y'):\n",
    "        self.length_samples = length_samples\n",
    "        self.excitation_sample = excitation_sample\n",
    "        self.pickup_sample = pickup_sample\n",
    "        self.length_left = self.excitation_sample # number of samples to left of excitation\n",
    "        self.length_right = self.length_samples - self.excitation_sample\n",
    "        self.d_r1 = DelayLine(self.length_left)\n",
    "        self.d_r2 = DelayLine(self.length_right)\n",
    "        self.d_l1 = DelayLine(self.length_left)\n",
    "        self.d_l2 = DelayLine(self.length_right)\n",
    "        self.set_initial_shape(np.zeros(length_samples))\n",
    "        if spring_k and spring_damping:\n",
    "            self.excitation_reflection_filter = DampedSpringReflectionFilter(k=spring_k, damping=spring_damping)\n",
    "        else:\n",
    "            self.excitation_reflection_filter = PointMassReflectionFilter(mass=excitation_mass)\n",
    "        # Bridge is a simple lowpass with slight damping at dc\n",
    "        self.bridge_filter = bridge_filter or OnePoleFilter(0.498, 0.498)\n",
    "        self.wave_variable_label = wave_variable_label\n",
    "        # This \"tension\" is only used to determine how much the slope neighboring the\n",
    "        # excitation \"pushes back\" against it.\n",
    "        self.tension = tension\n",
    "        self.excitation_type = excitation_type\n",
    "        self.picking_up = True # always start with picking upwards (if excitation_type is plectrum)\n",
    "        self.rest_excitation_y = 1.0\n",
    "        self.excitation_velocity = 0.0 # y-units-per-sample\n",
    "        self.deactivate_excitation(-self.rest_excitation_y)\n",
    "\n",
    "    def set_initial_shape(self, y_init):\n",
    "        y_r = y_init / 2\n",
    "        y_l = y_init / 2\n",
    "\n",
    "        self.d_r1.tick_all(y_r[:self.length_left][::-1])\n",
    "        self.d_r2.tick_all(y_r[self.length_left:][::-1])\n",
    "        self.d_l1.tick_all(y_l[:self.length_left])\n",
    "        self.d_l2.tick_all(y_l[self.length_left:])\n",
    "\n",
    "    # Set string shape back to 0s\n",
    "    def reset(self):\n",
    "        self.d_r1.clear()\n",
    "        self.d_r2.clear()\n",
    "        self.d_l1.clear()\n",
    "        self.d_l2.clear()\n",
    "\n",
    "    def get_all(self):\n",
    "        y_r1 = np.roll(self.d_r1.get_all(), -self.d_r1.read_sample)[::-1]\n",
    "        y_r2 = np.roll(self.d_r2.get_all(), -self.d_r2.read_sample)[::-1]\n",
    "        y_l1 = np.roll(self.d_l1.get_all(), -self.d_l1.read_sample)\n",
    "        y_l2 = np.roll(self.d_l2.get_all(), -self.d_l2.read_sample)\n",
    "        left_y = y_r1 + y_l1\n",
    "        right_y = y_r2 + y_l2\n",
    "        into_excitation = self.into_excitation()\n",
    "        excitation_y = self.excitation_y if into_excitation and not self.is_affixed() else (left_y[-1] + right_y[0]) / 2\n",
    "        return np.concatenate([left_y, [excitation_y], right_y])\n",
    "\n",
    "    # `velocity` is in units of y-units-per-sample.\n",
    "    # It's scaled to a reasonable scale relative to the max desired string displacement (+/- 1)\n",
    "    def trigger(self, velocity=1.0):\n",
    "        velocity = velocity / 8\n",
    "        self.excitation_reflection_filter.reset() # clear physical excitation state\n",
    "        if self.is_plectrum() or self.is_hammer():\n",
    "            if self.is_plectrum():\n",
    "                self.picking_up = not self.picking_up\n",
    "                if self.picking_up:\n",
    "                    self.activate_excitation(-self.rest_excitation_y, velocity)\n",
    "                else:\n",
    "                    self.activate_excitation(self.rest_excitation_y, -velocity)\n",
    "            elif self.is_hammer():\n",
    "                self.activate_excitation(-self.rest_excitation_y, velocity)\n",
    "        elif self.is_pluck() or self.is_affixed():\n",
    "            self.set_initial_shape(bandlimited_triangle_pluck(self.length_samples))\n",
    "        if self.is_affixed():\n",
    "            self.tick_excitation()\n",
    "\n",
    "    def tick(self, in_sample=0.0):\n",
    "        into_excitation_rightgoing = self.d_r1.get_tap(1)\n",
    "        into_right_termination = self.d_r2.get_tap(1)\n",
    "        into_excitation_leftgoing = self.d_l2.get_tap(1)\n",
    "        into_left_termination = self.d_l1.get_tap(1)\n",
    "\n",
    "        if not self.is_affixed():\n",
    "            self.tick_excitation()\n",
    "\n",
    "        into_excitation = self.into_excitation()\n",
    "        out_of_excitation = self.excitation_reflection_filter.tick(into_excitation) if into_excitation else 0\n",
    "\n",
    "        self.d_r1.tick(-self.bridge_filter.tick(into_left_termination) + in_sample)\n",
    "        self.d_l2.tick(-into_right_termination)\n",
    "        self.d_r2.tick(into_excitation_rightgoing + out_of_excitation)\n",
    "        self.d_l1.tick(into_excitation_leftgoing + out_of_excitation)\n",
    "\n",
    "        if self.is_affixed():\n",
    "            self.tick_excitation()\n",
    "        return self.tap_pickup()\n",
    "\n",
    "    def tick_excitation(self):\n",
    "        if not self.is_excitation_active():\n",
    "            return\n",
    "        if self.is_affixed():\n",
    "            self.excitation_y = (self.tap_pickup(self.excitation_sample - 1) + self.tap_pickup(self.excitation_sample)) / 2\n",
    "        elif self.is_hammer() or self.is_plectrum():\n",
    "            # force -> velocity\n",
    "            opposing_force = self.force_opposing_excitation()\n",
    "            if opposing_force > 0 and (self.is_hammer() or self.picking_up):\n",
    "                self.excitation_velocity -= opposing_force\n",
    "            elif opposing_force < 0 and self.is_plectrum() and not self.picking_up:\n",
    "                self.excitation_velocity -= opposing_force\n",
    "\n",
    "            # velocity -> displacement\n",
    "            self.excitation_y += self.excitation_velocity # hammer/plectrum driving into the string\n",
    "\n",
    "            # boundary conditions\n",
    "            if self.excitation_y < -self.rest_excitation_y:\n",
    "                self.deactivate_excitation(-self.rest_excitation_y)\n",
    "            elif self.excitation_y > self.rest_excitation_y and self.is_plectrum():\n",
    "                self.deactivate_excitation(self.rest_excitation_y)\n",
    "            elif self.is_plectrum():\n",
    "                if self.picking_up and self.excitation_velocity <= 0:\n",
    "                    self.deactivate_excitation(self.rest_excitation_y)\n",
    "                elif not self.picking_up and self.excitation_velocity >= 0:\n",
    "                    self.deactivate_excitation(-self.rest_excitation_y)\n",
    "\n",
    "    # How much is the string \"pushing back\" against the excitation mass?\n",
    "    # (Proportional to slope of string to left and right of excitation)\n",
    "    def force_opposing_excitation(self):\n",
    "        slope_to_left = self.excitation_y - self.tap_pickup(self.excitation_sample - 1)\n",
    "        slope_to_right = self.excitation_y - self.tap_pickup(self.excitation_sample)\n",
    "        unscaled_force = (slope_to_left + slope_to_right) / 2\n",
    "        return unscaled_force * self.tension\n",
    "\n",
    "    def into_excitation(self):\n",
    "        if not self.is_excitation_active():\n",
    "            return None\n",
    "\n",
    "        into_excitation_rightgoing = -self.d_r1.get_tap(1) # invert displacement wave variables\n",
    "        into_excitation_leftgoing = -self.d_l2.get_tap(1)\n",
    "        into_excitation = into_excitation_leftgoing + into_excitation_rightgoing\n",
    "        if self.is_affixed():\n",
    "            return into_excitation\n",
    "\n",
    "        # Non-affixed excitations introduce energy into the string if they are actively colliding with it.\n",
    "        into_excitation += self.excitation_y\n",
    "        is_colliding = into_excitation > 0 and (self.is_hammer() or (self.is_plectrum() and self.picking_up))\n",
    "        is_colliding = is_colliding or into_excitation < 0 and self.is_plectrum() and not self.picking_up\n",
    "        # `None` signals to the caller that there is no collision and the excitation should be ignored.\n",
    "        return into_excitation if is_colliding else None\n",
    "\n",
    "    def tap_pickup(self, pickup_sample=None):\n",
    "        pickup_sample = pickup_sample or self.pickup_sample\n",
    "        pickup_sample %= self.length_samples\n",
    "\n",
    "        if pickup_sample < self.length_left:\n",
    "            return self.d_r1.get_tap(-pickup_sample - 1) + self.d_l1.get_tap(pickup_sample)\n",
    "        else:\n",
    "            pickup_sample -= self.length_left\n",
    "            return self.d_r2.get_tap(-pickup_sample - 1) + self.d_l2.get_tap(pickup_sample)\n",
    "\n",
    "    def is_excitation_active(self):\n",
    "        return self.is_affixed() or self.excitation_active\n",
    "\n",
    "    def activate_excitation(self, excitation_y=None, excitation_velocity=None):\n",
    "        if excitation_y:\n",
    "            self.excitation_y = excitation_y\n",
    "        if excitation_velocity:\n",
    "            self.excitation_velocity = excitation_velocity\n",
    "        self.excitation_active = True\n",
    "\n",
    "    def deactivate_excitation(self, excitation_y=None):\n",
    "        self.excitation_active = False\n",
    "        if excitation_y:\n",
    "            self.excitation_y = excitation_y\n",
    "        self.excitation_velocity = 0\n",
    "\n",
    "    def is_affixed(self):\n",
    "        return self.excitation_type == self.ExcitationType.affixed\n",
    "    def is_plectrum(self):\n",
    "        return self.excitation_type == self.ExcitationType.plectrum\n",
    "    def is_hammer(self):\n",
    "        return self.excitation_type == self.ExcitationType.hammer\n",
    "    def is_pluck(self):\n",
    "        return self.excitation_type == self.ExcitationType.pluck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "\n",
    "def animate_waveguide_with_excitation(waveguide,\n",
    "                                      num_frames=None,\n",
    "                                      fps=10,\n",
    "                                      ticks_per_frame=1,\n",
    "                                      on_frame={}):\n",
    "    wv_label = waveguide.wave_variable_label\n",
    "    indices_left = np.arange(waveguide.length_left)\n",
    "    indices_right = np.arange(waveguide.length_right)\n",
    "    d_r1 = waveguide.d_r1\n",
    "    d_r2 = waveguide.d_r2\n",
    "    d_l1 = waveguide.d_l1\n",
    "    d_l2 = waveguide.d_l2\n",
    "\n",
    "    num_frames = num_frames or (waveguide.length_samples - 1) * 2\n",
    "\n",
    "    fig = plt.figure(constrained_layout=True, figsize=(14, 4 * 3))\n",
    "\n",
    "    gs = gridspec.GridSpec(figure=fig, nrows=4, ncols=2,\n",
    "                           width_ratios=[waveguide.length_left, waveguide.length_right])\n",
    "    y_plot = fig.add_subplot(gs[0, :])\n",
    "    y_r1_plot = fig.add_subplot(gs[1, 0])\n",
    "    y_r2_plot = fig.add_subplot(gs[1, 1])\n",
    "    y_l1_plot = fig.add_subplot(gs[2, 0])\n",
    "    y_l2_plot = fig.add_subplot(gs[2, 1])\n",
    "    pickup_plot = fig.add_subplot(gs[3, :])\n",
    "\n",
    "    y_plot.axvline(waveguide.pickup_sample, label='Pickup $x$', linewidth=3, c='black')\n",
    "    pickup_data = np.full(num_frames, np.nan)\n",
    "    pickup_data[0] = waveguide.tap_pickup()\n",
    "    pickup_ax, = pickup_plot.plot(pickup_data, c='black')\n",
    "    pickup_plot.set_xlim(0, num_frames - 1)\n",
    "    pickup_plot.set_ylim(-1.1, 1.1)\n",
    "    pickup_plot.grid(True)\n",
    "    pickup_plot.set_title('Signal from pickup at $x={}$'.format(waveguide.pickup_sample), size=16)\n",
    "    pickup_plot.set_xlabel('$t$ (samples) $\\\\longrightarrow$')\n",
    "\n",
    "    y_r1_ax, = y_r1_plot.plot(d_r1.get_all()[::-1], label='${}_1^+$'.format(wv_label),\n",
    "                              linestyle='--', c='b', alpha=0.7, linewidth=2)\n",
    "    y_r2_ax, = y_r2_plot.plot(d_r2.get_all()[::-1], label='${}_2^+$'.format(wv_label),\n",
    "                              linestyle='--', c='b', alpha=0.7, linewidth=2)\n",
    "    y_l1_ax, = y_l1_plot.plot(d_l1.get_all(), label='${}_1^-$'.format(wv_label),\n",
    "                              linestyle='--', c='b', alpha=0.7, linewidth=2)\n",
    "    y_l2_ax, = y_l2_plot.plot(d_l2.get_all(), label='${}_2^-$'.format(wv_label),\n",
    "                              linestyle='--', c='b', alpha=0.7, linewidth=2)\n",
    "\n",
    "    y_ax, = y_plot.plot(waveguide.get_all(), label='${0}^+ + {0}^-$'.format(wv_label), linewidth=3, c='b')\n",
    "\n",
    "    excitation_y_ax = y_plot.scatter([waveguide.excitation_sample], [waveguide.excitation_y], c='red', label='Excitation', zorder=10)\n",
    "\n",
    "    y_plot.set_title('${0}(t,x) = {0}^+(t,x) + {0}^-(t,x)$'.format(wv_label), size=16)\n",
    "    y_r1_plot.set_title('${}_1^+(t,x) \\\\rightarrow$'.format(wv_label), size=16)\n",
    "    y_r2_plot.set_title('${}_2^+(t,x) \\\\rightarrow$'.format(wv_label), size=16)\n",
    "    y_l1_plot.set_title('${}_1^-(t,x) \\\\leftarrow$'.format(wv_label), size=16)\n",
    "    y_l2_plot.set_title('${}_2^-(t,x) \\\\leftarrow$'.format(wv_label), size=16)\n",
    "\n",
    "    for plot in [y_plot, y_r1_plot, y_l1_plot]:\n",
    "        plot.set_ylabel('$y$')\n",
    "    for plot in [y_r2_plot, y_l2_plot]:\n",
    "        plot.set_yticklabels([])\n",
    "        plot.set_ylabel('-')\n",
    "    y_plot.set_xlim(0, waveguide.length_samples)\n",
    "    y_plot.set_xlabel('$x$')\n",
    "    for left_plot in [y_r1_plot, y_l1_plot]:\n",
    "        left_plot.set_xlim(0, indices_left.size - 1)\n",
    "        left_plot.set_xticks(indices_left)\n",
    "    for right_plot in [y_r2_plot, y_l2_plot]:\n",
    "        right_plot.set_xlim(0, indices_right.size - 1.03)\n",
    "        right_plot.set_xticks(indices_right)\n",
    "    \n",
    "    y_l1_plot.axvline(0.03, label='Bridge Filter $y_n=gx_n + py_{n-1}$', linewidth=3, c='purple')\n",
    "    y_r1_plot.axvline(indices_left.size - 1.03, label='Excitation Reflectance Filter $\\\\hat{\\\\rho}_{d}(z)$', linewidth=3, c='red')\n",
    "    y_r2_plot.axvline(indices_right.size - 1.03, label='Nut Filter $y_n=-x_n$', linewidth=3, c='green')\n",
    "    y_l2_plot.axvline(0.03, label='Excitation Reflectance Filter $\\\\hat{\\\\rho}_{d}(z)$', linewidth=3, c='red')\n",
    "\n",
    "    for plot in [y_r1_plot, y_r2_plot, y_l1_plot, y_l2_plot]:\n",
    "        plot.set_xlabel('Delay Line Sample Index')\n",
    "    for plot in [y_plot, y_r1_plot, y_r2_plot, y_l1_plot, y_l2_plot]:\n",
    "        plot.grid(True)\n",
    "        plot.set_ylim(-1.2, 1.2)\n",
    "        plot.legend(loc='upper right')\n",
    "\n",
    "    y_r1_plot.set_xticklabels(indices_left[::-1])\n",
    "    y_r2_plot.set_xticklabels(indices_right[::-1])\n",
    "\n",
    "    def animate(frame):\n",
    "        if frame < 1:\n",
    "            waveguide.trigger()\n",
    "            return\n",
    "\n",
    "        action = on_frame.get(frame)\n",
    "        if action:\n",
    "            action()\n",
    "\n",
    "        for _ in range(ticks_per_frame):\n",
    "            waveguide.tick()\n",
    "\n",
    "        y_r1_x = np.roll(indices_left, -d_r1.read_sample)[::-1]\n",
    "        y_r1 = d_r1.get_all()[y_r1_x]\n",
    "        y_r1_ax.set_ydata(y_r1)\n",
    "        y_r1_plot.set_xticklabels(y_r1_x)\n",
    "\n",
    "        y_r2_x = np.roll(indices_right, -d_r2.read_sample)[::-1]\n",
    "        y_r2 = d_r2.get_all()[y_r2_x]\n",
    "        y_r2_ax.set_ydata(y_r2)\n",
    "        y_r2_plot.set_xticklabels(y_r2_x)\n",
    "\n",
    "        y_l1_x = np.roll(indices_left, -d_l1.read_sample)\n",
    "        y_l1 = d_l1.get_all()[y_l1_x]\n",
    "        y_l1_ax.set_ydata(y_l1)\n",
    "        y_l1_plot.set_xticklabels(y_l1_x)\n",
    "\n",
    "        y_l2_x = np.roll(indices_right, -d_l2.read_sample)\n",
    "        y_l2 = d_l2.get_all()[y_l2_x]\n",
    "        y_l2_ax.set_ydata(y_l2)\n",
    "        y_l2_plot.set_xticklabels(y_l2_x)\n",
    "\n",
    "        y_ax.set_ydata(waveguide.get_all())\n",
    "        excitation_y_ax.set_offsets([waveguide.excitation_sample, waveguide.excitation_y])\n",
    "        excitation_y_ax.set_color('red' if waveguide.is_excitation_active() else 'gray')\n",
    "\n",
    "        pickup_data[frame] = waveguide.tap_pickup()\n",
    "        pickup_ax.set_ydata(pickup_data)\n",
    "\n",
    "    return create_animation(fig, plt, animate, frames=num_frames, frames_per_second=fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Affixed Mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "animation_string_samples = 42\n",
    "length_samples = animation_string_samples\n",
    "waveguide = WaveguideWithExcitation(length_samples=length_samples, \n",
    "                                    excitation_type=WaveguideWithExcitation.ExcitationType.affixed,\n",
    "                                    excitation_sample=length_samples // 3,\n",
    "                                    pickup_sample=length_samples // 5,\n",
    "                                    excitation_mass=5.0)\n",
    "\n",
    "waveguide.trigger()\n",
    "animate_waveguide_with_excitation(waveguide, num_frames=waveguide.length_samples*4, fps=10, ticks_per_frame=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* We now have _four_ delay lines in our model - one for each traveling wave direction on each side of the attached mass.\n",
    "* We now have _three_ filters in our model - the filters we've already seen at the \"bridge\" (left) and \"nut\" (right), as well as the new excitation reflectance filter\n",
    "* We can imagine a single sample of string displacement traveling through the model like this:\n",
    "  - Start at the top-left and travel to the right through the ($y_1^+$) delay line\n",
    "  - When hitting the attached mass scattering junction, _reflect_ (and invert) part of my displacement into the right side of the bottom-left ($y_1^-$) delay line and start traveling through it to the left\n",
    "  - The remainder of my displacement will be _trasmitted_ through the junction to the _right_ of the mass ($y_2^+$), and start traveling through it to the right\n",
    "  - When I hit the right non-yielding termination (\"nut\"), I get reflected into the lower-right delay line ($y_2^-$) and start traveling through it to the left.\n",
    "  - When hitting the attached mass scattering junction for the second time, reflect (and invert) part of my displacement into the left side of the top-right ($y_2^+$) delay line and start traveling through it to the right\n",
    "  - The remainder of my displacement will be trasmitted into the delay line to the _left_ of the mass ($y_1^-$)\n",
    "  - Finally, when I run into the \"bridge\" at the left end of $y_1^-$, reflect some of my displacement back into the top-left delay-line where I started. Some part of it will be transmitted into the instrument body via the bridge. (This is still the only lossy part of the model.)\n",
    "* Since the mass in this example is _light_, notice how the lowest frequency energy is still allowed through, while higher frequency energy is reflected.\n",
    "* No energy is _introduced_ into the string by the mass - what's not reflected from it is trasmitted through.\n",
    "\n",
    "Let's listen to what this sounds like (the only thing changing is the delay line length):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "length_samples = a_samples\n",
    "waveguide = WaveguideWithExcitation(length_samples=length_samples, \n",
    "                                    excitation_type=WaveguideWithExcitation.ExcitationType.affixed,\n",
    "                                    excitation_sample=length_samples // 3,\n",
    "                                    pickup_sample=length_samples // 5,\n",
    "                                    excitation_mass=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "waveguide.trigger()\n",
    "Audio([waveguide.tick() for _ in range(fs * 6)], rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We can clearly hear at least two disctinct tones. This is because we effectively have _three_ different string lengths interacting with each other - the string to the left of the mass, the string to the right, and the full string length.  The main tone still comes from the full string length, and the other buzzing tone comes from higher frequencies alternating between the left and right string sections. It's buzzy mostly because of a discontinuity introduced a the beginning, as the one-pole filter \"warms up\" its state (its history starts with a single zero value).\n",
    "\n",
    "Now let's look at the behavior of a _heavy_ affixed mass:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A heavier affixed mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "animation_string_samples = 42\n",
    "length_samples = animation_string_samples\n",
    "waveguide = WaveguideWithExcitation(length_samples=length_samples, \n",
    "                                    excitation_type=WaveguideWithExcitation.ExcitationType.affixed,\n",
    "                                    excitation_sample=length_samples // 3,\n",
    "                                    pickup_sample=length_samples // 5,\n",
    "                                    excitation_mass=80.0)\n",
    "\n",
    "waveguide.trigger()\n",
    "animate_waveguide_with_excitation(waveguide, num_frames=waveguide.length_samples*4, fps=10, ticks_per_frame=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Notice how the _heavy_ mass prevents reflects all but just a little bit of low-frequency energy. It's not _quite_ heavy enough to act like a fully rigid termination, though - it still moves up and down a little bit.\n",
    "\n",
    "Here's what it sounds like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "length_samples = a_samples\n",
    "waveguide = WaveguideWithExcitation(length_samples=length_samples, \n",
    "                                    excitation_type=WaveguideWithExcitation.ExcitationType.affixed,\n",
    "                                    excitation_sample=length_samples // 3,\n",
    "                                    pickup_sample=length_samples // 5,\n",
    "                                    excitation_mass=100.0)\n",
    "waveguide.trigger()\n",
    "Audio([waveguide.tick() for _ in range(fs * 6)], rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This one sounds much more unusual! The pickup is placed to the left of the mass, so we hear a detuned sound composed mainly of the frequency relationship between the left half of the string and the entire string length. But we also get a buzzy higher-frequency tone that persists for longer than the rest of the sustain. Remember that the right-termination (the nut) doesn't attenuate _any_ frequencies. Since the heavy mass acts _almost_ as a rigid termination itself, the energy in the right half of the string is maintained for much longer. Only the small amount of low-frequency energy that \"leaks through\" the heavy affixed mass is able to be slowly dissippated through the yielding bridge. The high-frequency components are reflected almost completely and will be \"stuck\" in the right half of the string. It helps to again think of why this is the case, physically. High frequencies mean displacements are alternating rapidly between positive and negative values. The heavier the mass, the longer it takes for the mass to react to being \"hit\" by the energy of a large string displacement. Before it's able to react and move (yield), it gets pushed back in the opposite direction. The net result is that the mass effectively doesn't move at all in reaction to the high frequencies, and thus acts as a rigid termination for higher frequencies.\n",
    "\n",
    "As we would expect, if we listen to what's happening to the _right_ of the mass, we'll be able to tap into those \"trapped\" high frequencies, and the low frequencies of the entire string will decay out at the normal rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "length_samples = a_samples\n",
    "waveguide = WaveguideWithExcitation(length_samples=length_samples, \n",
    "                                    excitation_type=WaveguideWithExcitation.ExcitationType.affixed,\n",
    "                                    excitation_sample=length_samples // 3,\n",
    "                                    pickup_sample=4 * length_samples // 5,\n",
    "                                    excitation_mass=100.0)\n",
    "waveguide.trigger()\n",
    "Audio([waveguide.tick() for _ in range(fs * 6)], rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Up to this point, the only way we've introduced energy into the string is by initializing the string position.\n",
    "\n",
    "Most stringed instruments, however, are _excited_ by an external force like a guitar pick (plectrum) or a piano hammer.\n",
    "\n",
    "First we consider the case of a _hammer_, which we will currently treat as our point mass colliding with the string from below. When the hammer is _in contact_ with the string, it displaces the string and introduces our mass scattering junction. In this specific model, I make the string \"push back\" on the hammer with a force proportional to the string slope directly surrounding the hammer point. I disengage the hammer (shown as gray) after it returns to a displacement of -1, in order to keep it in view but prevent any buzzing if the string rebounds back and hits it. (In a realtime instrument, all of these considerations could be provided as controls.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Incorporating Control Motion and Collision Detection\n",
    "\n",
    "## Picking motion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Let's stick with our simple mass for a bit, and introduce a new control motion aspect - picking up and down.\n",
    "\n",
    "In my model, the only change between a hammer and pick is that when the velocity of the pick starts to encounter enough resistance to _reverse direction_, it instead \"slips off\" of the string, and deactivates. Also, I store a little state to track whether we're picking up or down:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "length_samples = animation_string_samples\n",
    "waveguide = WaveguideWithExcitation(length_samples=length_samples,\n",
    "                                    pickup_sample=length_samples//6,\n",
    "                                    excitation_sample=length_samples//4,\n",
    "                                    excitation_type=WaveguideWithExcitation.ExcitationType.plectrum,\n",
    "                                    excitation_mass=8.0)\n",
    "num_frames = waveguide.length_samples * 5\n",
    "on_frame = {\n",
    "    # trigger again halfway through to pick back down\n",
    "    num_frames // 2: lambda: waveguide.trigger()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "animate_waveguide_with_excitation(waveguide, num_frames=num_frames, fps=20, ticks_per_frame=1, on_frame=on_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "waveguide_out = np.zeros(fs * 10)\n",
    "\n",
    "length_samples = a_samples\n",
    "waveguide = WaveguideWithExcitation(length_samples=length_samples,\n",
    "                                    pickup_sample=length_samples//6,\n",
    "                                    excitation_sample=length_samples//4,\n",
    "                                    excitation_type=WaveguideWithExcitation.ExcitationType.plectrum,\n",
    "                                    excitation_mass=5.0)\n",
    "\n",
    "for i in range(waveguide_out.size):\n",
    "    if i < fs * 5 and i % (fs // 6) == 0: # every 6th of a second starting at t=0, trigger again\n",
    "        waveguide.trigger(np.random.rand())\n",
    "    waveguide_out[i] = waveguide.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Audio(waveguide_out, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## A heavier mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "waveguide_out = np.zeros(fs * 10)\n",
    "\n",
    "length_samples = a_samples\n",
    "waveguide = WaveguideWithExcitation(length_samples=length_samples,\n",
    "                                    pickup_sample=length_samples//6,\n",
    "                                    excitation_sample=length_samples//4,\n",
    "                                    excitation_type=WaveguideWithExcitation.ExcitationType.plectrum,\n",
    "                                    excitation_mass=200.0)\n",
    "\n",
    "for i in range(waveguide_out.size):\n",
    "    if i < fs * 5 and i % (fs // 6) == 0: # every 6th of a second starting at t=0, trigger again\n",
    "        waveguide.trigger(np.random.rand())\n",
    "    waveguide_out[i] = waveguide.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Audio(waveguide_out, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Strum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../musimathics/')\n",
    "from pitches import frequencies_for_note_labels\n",
    "from Filters import IirFilter\n",
    "\n",
    "class Guitar:\n",
    "    def __init__(self, with_string_coupling=True):\n",
    "        frequencies = frequencies_for_note_labels(['E3', 'A3', 'D4', 'G4', 'B4', 'E5'])\n",
    "        sample_lengths = [round(fs / f) for f in frequencies] # TODO support fractional delay lengths\n",
    "        self.strings = [WaveguideWithExcitation(length_samples=length_samples,\n",
    "                                                pickup_sample=length_samples//6,\n",
    "                                                excitation_sample=length_samples//4,\n",
    "                                                excitation_type=WaveguideWithExcitation.ExcitationType.hammer,\n",
    "                                                excitation_mass=10.0) for length_samples in sample_lengths]\n",
    "        self.with_string_coupling = with_string_coupling\n",
    "        if with_string_coupling:\n",
    "            self.coupling_filter = IirFilter([0.1], [1.0, -0.9]) # one-pole\n",
    "        self.coupling_gain = 0.007\n",
    "        self.previous_out = 0.0\n",
    "\n",
    "    def tick(self):\n",
    "        out = 0.0\n",
    "        for string in self.strings:\n",
    "            if self.with_string_coupling:\n",
    "                coupling_out = self.coupling_gain * self.coupling_filter.tick(self.previous_out)\n",
    "                out += string.tick(coupling_out)\n",
    "            else:\n",
    "                out += string.tick()\n",
    "\n",
    "        self.previous_out = out\n",
    "        return out\n",
    "\n",
    "    def trigger(self, velocity=1.0, string_index=None):\n",
    "        string_index = string_index if string_index is not None else np.random.randint(len(self.strings))\n",
    "        self.strings[string_index].trigger(velocity)\n",
    "    \n",
    "    # Convenience method to play all the string in short succession,\n",
    "    # with gaps between triggers set by `trigger_delay`\n",
    "    def strum(self, string_indices=np.arange(6), num_samples=fs*10, trigger_delay=fs//12):\n",
    "        out = np.zeros(num_samples)\n",
    "        for i in range(num_samples):\n",
    "            if i % trigger_delay == 0 and i//trigger_delay < len(string_indices):\n",
    "                string_index = string_indices[i//trigger_delay]\n",
    "                self.trigger(np.random.uniform(low=0.5, high=1.0), string_index=string_index)\n",
    "            out[i] = self.tick()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "guitar = Guitar()\n",
    "string_indices = np.concatenate([np.arange(6), np.arange(6)[::-1]])\n",
    "strum_samples = guitar.strum(string_indices=string_indices, num_samples=fs*10)\n",
    "Audio(strum_samples, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Impulse response for guitar body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read as read_wav\n",
    "from IPython.display import Audio\n",
    "\n",
    "# From https://www.3sigmaaudio.com/items/category/classical-guitars/\n",
    "fs, ir_samples = read_wav('classical_guitar_ir_16b.wav')\n",
    "ir_samples = ir_samples / ir_samples.max() # normalize to [-1, 1]\n",
    "Audio(ir_samples, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def convolve(x, y):\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    flipped_y = flip(y)\n",
    "    convolved = np.zeros(x.size + y.size - 1)\n",
    "    if x.dtype == complex or y.dtype == complex:\n",
    "        convolved = convolved.astype(complex)\n",
    "    for n in range(convolved.size):\n",
    "        convolved[n] = np.sum(x * shift(flipped_y, n))\n",
    "    return convolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_with_clipped_edges(x, y, **args):\n",
    "    return plt.plot(np.concatenate([[x[0]], x, [x[-1]]]), np.concatenate([[0], y, [0]]), **args)\n",
    "\n",
    "def create_convolution_animation(f, g, normalize=False, title='', length_seconds=3.5):\n",
    "    f = np.asarray(f)\n",
    "    g = np.asarray(g)\n",
    "    x_max = len(f) * 5\n",
    "    num_frames = x_max + len(g) + 1\n",
    "\n",
    "    f = f / f.max()\n",
    "    fig = plt.figure(figsize=(10.5, 2))\n",
    "    plt.title(title)\n",
    "    plt.axhline(color='black', linewidth=0.5)\n",
    "    f_start = (x_max - len(f)) // 2\n",
    "    f_line, = plot_with_clipped_edges(np.arange(len(f)) + f_start, f, c='b', label='$x$')\n",
    "    g_line, = plot_with_clipped_edges(np.arange(-len(g), 0), g, c='r', label='$y$')\n",
    "    convolution = np.convolve(f, g)\n",
    "    if normalize:\n",
    "        convolution = convolution / np.abs(convolution).max()\n",
    "    revealed_convolution = np.full(len(convolution), np.nan)\n",
    "    conv_line, = plt.plot(np.arange(len(convolution)) + (x_max - len(convolution)) / 2, revealed_convolution, label='$y = conv(x, y)$', linewidth=3)\n",
    "    plt.axis([0, x_max, min(0, convolution.min(), f.min(), g.min()), max(1, convolution.max(), f.max(), g.max()) + 0.1])\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    def animate(i):\n",
    "        g_data = g_line.get_xdata() + 1\n",
    "        g_line.set_xdata(g_data) # step convolution to the right\n",
    "        g_pos = g_data[0]\n",
    "        if g_pos + len(g) >= f_start and g_pos < f_start + len(f):\n",
    "            n_revealed = g_pos + len(g) - f_start\n",
    "            revealed_convolution[:n_revealed] = convolution[:n_revealed]\n",
    "        conv_line.set_ydata(revealed_convolution)\n",
    "    return create_animation(fig, plt, animate, length_seconds=length_seconds, frames_per_second=num_frames/length_seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = [1.0] * 10 + [0.5] * 10 + [0] * 20\n",
    "h = np.exp(-np.arange(40))\n",
    "create_convolution_animation(x, h[::-1], normalize=True, title='Convolution: ADSR Envelope')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.signal import convolve\n",
    "strum_with_body = convolve(strum_samples, ir_samples)\n",
    "\n",
    "Audio(strum_with_body, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 2: Piano\n",
    "\n",
    "## Commuted Synthesis\n",
    "\n",
    "![](https://flylib.com/books/2/729/1/html/2/images/0131089897/graphics/01fig10.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Excitation Signals into Simple String Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from Filters import TwoZeroFilter, PoleZeroFilter, OnePoleFilter, IirFilter\n",
    "sys.path.append('../musimathics')\n",
    "from pitches import frequency_for_note_label, frequencies_for_note_labels\n",
    "note2freq = frequency_for_note_label\n",
    "notes2freqs = frequencies_for_note_labels\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "%matplotlib inline\n",
    "from scipy.signal import freqz\n",
    "from IPython.display import Audio\n",
    "\n",
    "from DelayLine import DelayLine\n",
    "from SamplePlayer import SamplePlayer, WavPlayer\n",
    "from AllpassDelay import AllpassDelay\n",
    "\n",
    "fs = sample_rate = 44100\n",
    "lowest_frequency = note2freq('A0')\n",
    "highest_frequency = note2freq('C8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.signal import lfilter\n",
    "\n",
    "soundboard_player = WavPlayer('soundboard.wav', normalize=True)\n",
    "\n",
    "excite_size = soundboard_player.samples.size\n",
    "noise = np.random.uniform(low=-1, high=1, size=excite_size)\n",
    "decaying_noise = noise * np.exp(-np.linspace(0, 24, excite_size)) # found exp constant visually\n",
    "filtered_decaying_noise = lfilter(b=[0.03], a=[1, -0.97], x=decaying_noise)\n",
    "filtered_decaying_noise /= filtered_decaying_noise.max()\n",
    "\n",
    "def plot_excitation_signals():\n",
    "    fig, axes = plt.subplots(5, 1, figsize=(10, 12))\n",
    "    t = np.arange(excite_size) / soundboard_player.fs\n",
    "    axes[0].plot(t, noise)\n",
    "    axes[0].grid(True)\n",
    "    axes[0].set_title('Noise Signal')\n",
    "    axes[0].set_xlabel('Time (s)')\n",
    "    axes[0].set_ylabel('Amplitude')\n",
    "\n",
    "    axes[1].plot(t, decaying_noise)\n",
    "    axes[1].grid(True)\n",
    "    axes[1].set_title('Exponentially Decaying Noise')\n",
    "    axes[1].set_xlabel('Time (s)')\n",
    "    axes[1].set_ylabel('Amplitude')\n",
    "    \n",
    "    w, H = freqz([0.03], [1, -0.97])\n",
    "    axes[2].plot(w, 20 * np.log10(np.abs(H)), c='red')\n",
    "    axes[2].grid(True)\n",
    "    axes[2].set_title('LP Filter')\n",
    "    axes[2].set_xlabel('Frequency (radians/sample)')\n",
    "    axes[2].set_ylabel('Magnitude (dB)')\n",
    "\n",
    "    axes[3].plot(t, filtered_decaying_noise)\n",
    "    axes[3].grid(True)\n",
    "    axes[3].set_title('LP-Filtered Exponentially Decaying Noise')\n",
    "    axes[3].set_xlabel('Time (s)')\n",
    "    axes[3].set_ylabel('Normalized Amplitude')\n",
    "    \n",
    "    axes[4].plot(t, soundboard_player.samples)\n",
    "    axes[4].grid(True)\n",
    "    axes[4].set_title('Measured Piano Soundboard Impulse Response')\n",
    "    axes[4].set_xlabel('Time (s)')\n",
    "    axes[4].set_ylabel('Normalized amplitude')\n",
    "    \n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plot_excitation_signals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "out_samples = np.zeros(fs * 10) # keep reusing this to limit memory allocation and speed things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def string_loop(exciter=soundboard_player,\n",
    "                frequency=frequency_for_note_label('A3'),\n",
    "                loop_filter=OnePoleFilter(0.497, 0.497)): # simplest lowpass slightly damped at dc\n",
    "    delay_length = sample_rate / frequency\n",
    "    delay = AllpassDelay(delay_length, int(delay_length + 2))\n",
    "    exciter.reset()\n",
    "    for i in range(len(out_samples)):\n",
    "        into_string = exciter.tick() + loop_filter.tick(delay.get_next_out())\n",
    "        out_samples[i] = delay.tick(into_string)\n",
    "    return out_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Audio(noise, rate=soundboard_player.fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Audio(string_loop(exciter=SamplePlayer(noise)), rate=soundboard_player.fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Audio(decaying_noise, rate=soundboard_player.fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Audio(string_loop(exciter=SamplePlayer(decaying_noise)), rate=soundboard_player.fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Audio(filtered_decaying_noise, rate=soundboard_player.fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Audio(string_loop(exciter=SamplePlayer(filtered_decaying_noise)), rate=soundboard_player.fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Audio(soundboard_player.samples, rate=soundboard_player.fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Audio(string_loop(exciter=soundboard_player), rate=soundboard_player.fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Audio(string_loop(exciter=soundboard_player, frequency=note2freq('C5')), rate=soundboard_player.fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "soundboard_player_exp = SamplePlayer(soundboard_player.samples * np.exp(-np.linspace(0, 3, excite_size)))\n",
    "Audio(string_loop(exciter=soundboard_player_exp, frequency=note2freq('C5')), rate=soundboard_player.fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Loop Filter Design\n",
    "## Energy Decay Relief (not using)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def index_closest_to_value(array, value):\n",
    "    return np.abs(array - value).argmin()\n",
    "\n",
    "from scipy.signal import spectrogram\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "from matplotlib import cm\n",
    "\n",
    "def plot_edr(signal, fs=fs, nfft=1024, frequency_cutoff=6_000, harmonic_frequencies=None):\n",
    "    # frame_size_ms = 30 # minimum frame length, in ms\n",
    "    # overlap = 0.75 # fraction of frame overlapping\n",
    "    # min_frame_length = int(fs * frame_size_ms / 1000)\n",
    "    # Calculate fft size = next power of 2\n",
    "    # frame_length = 2 ** int(np.ceil(np.log2(min_frame_length)))\n",
    "    # F, T, B = spectrogram(signal, fs, 'hann', frame_length, overlap*frame_length)\n",
    "    \n",
    "    # default `spectrogram` overlap value, which will be used to calculate decay times later\n",
    "    overlap_samples=256//8\n",
    "    F, T, B = spectrogram(signal, fs, 'hann', noverlap=256//8, nfft=nfft)\n",
    "\n",
    "    frequency_indices = np.arange(np.argmax(F > frequency_cutoff)) if harmonic_frequencies is None else [index_closest_to_value(F, frequency) for frequency in harmonic_frequencies]\n",
    "    F = F[frequency_indices]\n",
    "    B = B[frequency_indices,:]\n",
    "    B_energy = B * np.conj(B)\n",
    "    B_edr = np.fliplr(np.cumsum(np.fliplr(B_energy), axis=1))\n",
    "    B_edr = 10 * np.log10(np.abs(B_edr)) # convert to dB\n",
    "    B_edr -= B_edr.max() # normalize to 0 dB\n",
    "    db_cutoff = -120\n",
    "    B_edr = np.clip(B_edr, a_min=db_cutoff, a_max=None) # truncate below cutoff dB\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    if harmonic_frequencies is None:\n",
    "        ax.plot_surface(*np.meshgrid(T, F/1000), B_edr, rstride=1, cstride=4, antialiased=False, cmap=cm.coolwarm)\n",
    "        ax.set_ylabel('Frequency (kHz)')\n",
    "    else:\n",
    "        ax.plot_wireframe(*np.meshgrid(T, F/1000), B_edr, rstride=1, cstride=nfft // 20, antialiased=True, cmap=cm.coolwarm, linewidth=3)\n",
    "        ax.set_yticks(F / 1000)\n",
    "        ax.set_yticklabels(np.arange(F.size) + 1)\n",
    "        ax.set_ylabel('Harmonic #')\n",
    "\n",
    "    ax.view_init(30, 30) # orientation\n",
    "    plt.title('Normalized Energy Decay Relief (EDR)', size=16)\n",
    "    ax.set_xlabel('Time (s)'); _ = ax.set_zlabel('Magnitude (dB)')\n",
    "    ax.set_zlim(db_cutoff + 2, 0) # + 2 hack to avoid small extra space matplotlib pads the z axis with\n",
    "    return F, T, B_edr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read as read_wav\n",
    "fs_d4, d4 = read_wav('D4.wav')\n",
    "Audio(d4, rate=fs_d4)\n",
    "\n",
    "F, T, B_edr = plot_edr(d4, fs_d4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fundamental_frequency = note2freq('D4')\n",
    "# higher `nfft` to get frequency bins with better alignment to exact harmonics\n",
    "harmonic_frequencies = fundamental_frequency*np.arange(1, 13)\n",
    "F, T, B_edr = plot_edr(d4, fs_d4, nfft=5096, harmonic_frequencies=harmonic_frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Loop Filter Design\n",
    "## Simple Filter with Brightness and Sustain Controls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "### Length Three FIR Loop Filter with Brightness and Sustain\n",
    "\n",
    "If we relax the DC normalization constraint so that two degrees of freedom are retained, we can then conveniently control the loop filter with a _brightness_ $B$ and a _sustain_ $S$ according to\n",
    "\n",
    "$\\begin{align}\n",
    "g_0 &= e^{-6.91P/S}\\\\\n",
    "g(0) &= g_0(1 + B) / 2\\\\\n",
    "g(1) &= g_0(1 - B) / 4\\\\\n",
    "\\end{align}$,\n",
    "\n",
    "where $P$ is the period in seconds (total loop delay), $S$ is the desired sustain time in seconds, the sustain parameter $S$ is the time to decay by -60 dB (or $\\approx$ 6.91 time-constants) when brightness $B$ is maximum ($B = 1$) in which case the loop gain is $g_0$ at all frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Length-3 FIR filter with sustain and brightness controls\n",
    "# From https://ccrma.stanford.edu/~jos/pasp/Length_FIR_Loop_Filter.html\n",
    "def sustain_brightness_filter(sustain_seconds, brightness, frequency):\n",
    "    g0 = np.exp(-6.91 / (sustain_seconds * frequency))\n",
    "    b0 = g0 * (1 + brightness) / 2.0\n",
    "    b1 = g0 * (1 - brightness) / 4.0\n",
    "    loop_filter = TwoZeroFilter()\n",
    "    loop_filter.set_coefficients(b1, b0, b1)\n",
    "\n",
    "    return loop_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def create_loop_filter_brightness_sustain_animation(animation_length_seconds=1):\n",
    "    fig, frequency_plot = plt.subplots(1, 1, figsize=(10, 4))\n",
    "\n",
    "    num_frames = DEFAULT_FPS * animation_length_seconds\n",
    "\n",
    "    def animate(frame):\n",
    "        brightness = 1 - frame / (num_frames - 1)\n",
    "        sustain = np.exp(frame / 5)\n",
    "        loop_delay_sec = 1 # assume loop delay of 1 sec for simplicity\n",
    "        fig.suptitle('Length-3 FIR Loop Filter with Brightness ($B$) and Sustain ($S$) Controls\\n$B={%0.2f}, S={%0.1f}$ sec' % (brightness, sustain), size=18)\n",
    "        t60 = 6.91 # time-constants to decay to -60dB\n",
    "        g = np.exp(-t60 * loop_delay_sec / sustain)\n",
    "        g_0 = g * (1 + brightness) / 2\n",
    "        g_1 = g * (1 - brightness) / 4\n",
    "        b = [g_1, g_0, g_1]\n",
    "        w, H = freqz(b, [1])\n",
    "\n",
    "        frequency_plot.cla()\n",
    "        plot_frequency_response(w, H, fig=fig, frequency_plot=frequency_plot, show_phase_plot=False, db=False)\n",
    "        plt.subplots_adjust(top=0.70)    \n",
    "\n",
    "    return create_animation(fig, plt, animate, length_seconds=animation_length_seconds, default_mode='reflect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "create_loop_filter_brightness_sustain_animation(animation_length_seconds=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "notes_with_varying_sustain = [\n",
    "    Audio(string_loop(loop_filter=sustain_brightness_filter(sustain, 0.6, note2freq('C5')),\n",
    "                      exciter=soundboard_player_exp,\n",
    "                      frequency=note2freq('A4')),\n",
    "          rate=soundboard_player.fs)\n",
    "    for sustain in [0.1, 1.0, 5.0]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### 0.1 seconds of sustain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "notes_with_varying_sustain[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### 1 second of sustain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "notes_with_varying_sustain[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### 5 seconds of sustain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "notes_with_varying_sustain[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "notes_with_varying_brightness = [\n",
    "    Audio(string_loop(loop_filter=sustain_brightness_filter(3.0, brightness, note2freq('C5')),\n",
    "                      exciter=soundboard_player_exp,\n",
    "                      frequency=note2freq('A4')),\n",
    "          rate=soundboard_player.fs)\n",
    "    for brightness in np.linspace(0.01, 1.0, 3)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Low brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "notes_with_varying_brightness[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### High brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "notes_with_varying_brightness[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# String Coupling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Initial t60s range from 15 seconds (A0) to 0.3 seconds (C8)\n",
    "# Sustained t60s range from 50 seconds (A0) to 0.3 seconds (C8)\n",
    "# From:\n",
    "# Fletcher and Rossing \"The Physics of Musical Instruments\", 2nd edition\n",
    "# Springer-Verlag, New York, 1998, p. 384\n",
    "def initial_and_sustained_t60s(frequency,\n",
    "                               max_initial_t60_sec=15.0, max_sustained_t60_sec=50.0):\n",
    "    low_freq_log10_t60s = np.log10([max_initial_t60_sec, max_sustained_t60_sec])\n",
    "    t60_scalar = (frequency - lowest_frequency) / (highest_frequency - lowest_frequency)\n",
    "    t60s = 10.0 ** (low_freq_log10_t60s - t60_scalar * (low_freq_log10_t60s - np.log10(0.3)))\n",
    "    t60_initial = t60s[0]\n",
    "    t60_sustain = t60s[1]\n",
    "    return t60_initial, t60_sustain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_initial_and_sustained_t60s(max_initial_t60_sec=15.0, max_sustained_t60_sec=50.0):\n",
    "    frequencies = np.linspace(lowest_frequency, highest_frequency, 100)\n",
    "    plt.figure(figsize=(16, 4))\n",
    "    plt.plot(frequencies,\n",
    "             [initial_and_sustained_t60s(frequency,\n",
    "                                         max_initial_t60_sec=max_initial_t60_sec,\n",
    "                                         max_sustained_t60_sec=max_sustained_t60_sec)\n",
    "              for frequency in frequencies],\n",
    "             linewidth=3, alpha=0.7)\n",
    "    plt.legend(['Inital', 'Sustain'])\n",
    "    plt.title('Initial and Sustained t60s by Frequency, Ranging from $A0$ to $C8$', size=16)\n",
    "    plt.xlim(frequencies[0], frequencies[-1])\n",
    "    plt.xticks(np.linspace(frequencies[0], frequencies[-1], 10))\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    _ = plt.ylabel('t60 (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plot_initial_and_sustained_t60s(max_initial_t60_sec=9.0, max_sustained_t60_sec=20.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Simple utility to chain filters serially, used for dispersion filter which we'll cover later.\n",
    "class FilterChain:\n",
    "    def __init__(self, filters=[]):\n",
    "        self.filters = filters\n",
    "    \n",
    "    def tick(self, in_sample):\n",
    "        out_sample = in_sample\n",
    "        for f in self.filters:\n",
    "            out_sample = f.tick(out_sample)\n",
    "        return out_sample\n",
    "    \n",
    "    def clear(self):\n",
    "        for f in self.filters:\n",
    "            f.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def string_loop_with_detuning(exciter=soundboard_player_exp,\n",
    "                              frequency=note2freq('A4'),\n",
    "                              frequency_jitter=0.002,\n",
    "                              detuning=0.9993,\n",
    "                              brightness=0.8,\n",
    "                              strike_position=None, # No comb delay by default\n",
    "                              max_initial_t60_sec=9.0,\n",
    "                              max_sustained_t60_sec=20.0,\n",
    "                              onset_sample=0,\n",
    "                              gain=1.0,\n",
    "                              # We'll get to dispersion filters later!\n",
    "                              # This function should take a frequency and return a\n",
    "                              # (filter, delay_compensation_samples) pair.\n",
    "                              dispersion_filter_fn=None):\n",
    "\n",
    "    if onset_sample == 0: # First note - reset the global samples array\n",
    "        out_samples[:] = 0.0\n",
    "\n",
    "    delay_length = sample_rate / frequency\n",
    "    # slight detuning across the entire \"string\" for realism\n",
    "    delay_length *= 1.0 + (np.random.uniform(low=-frequency_jitter, high=frequency_jitter) if frequency_jitter else 0)\n",
    "\n",
    "    # minus 2 to compensate for extra filtering\n",
    "    filter_delays = [-2,-2]\n",
    "    dispersion_filters = None\n",
    "    if dispersion_filter_fn is not None:\n",
    "        dispersion_filters = [dispersion_filter_fn(frequency), dispersion_filter_fn(frequency * detuning)]\n",
    "        for i in range(len(filter_delays)):\n",
    "            filter_delays[i] += dispersion_filters[i][1]\n",
    "\n",
    "    # Generalize to N strings\n",
    "    delay_lines = [\n",
    "        AllpassDelay(delay_length + filter_delays[0], int(delay_length)),\n",
    "        AllpassDelay(delay_length * detuning + filter_delays[1], int(delay_length * detuning))\n",
    "    ]\n",
    "\n",
    "    t60_initial, t60_sustain = initial_and_sustained_t60s(frequency,\n",
    "                                                          max_initial_t60_sec=max_initial_t60_sec,\n",
    "                                                          max_sustained_t60_sec=max_sustained_t60_sec)\n",
    "    loop_filters = [\n",
    "        sustain_brightness_filter(t60_initial, brightness, frequency),\n",
    "        sustain_brightness_filter(t60_sustain, brightness, frequency * detuning)\n",
    "    ]\n",
    "\n",
    "    if dispersion_filters is not None:\n",
    "        for i in range(len(loop_filters)):\n",
    "            loop_filters[i] = FilterChain([loop_filters[i], dispersion_filters[i][0]])\n",
    "\n",
    "    if strike_position:\n",
    "        strike_comb_delay = AllpassDelay(strike_position * delay_length, int(delay_length + 1))\n",
    "\n",
    "    exciter.reset()\n",
    "\n",
    "    delay_line_outs = [0.0, 0.0]\n",
    "\n",
    "    for i in range(out_samples.size - onset_sample):\n",
    "        in_sample = exciter.tick()\n",
    "        gen_input = in_sample - (strike_comb_delay.tick(in_sample) if strike_position else 0.0)\n",
    "\n",
    "        delay_line_outs[0] = loop_filters[0].tick(delay_lines[0].tick(gen_input + delay_line_outs[0]))\n",
    "        # A hack to futher emulate a stronger attack.\n",
    "        # Note that this technically invalidates the sustain t60 value.\n",
    "        long_sustain_excite_gain = 0.6\n",
    "        delay_line_outs[1] = loop_filters[1].tick(delay_lines[1].tick(long_sustain_excite_gain *\n",
    "                                                                      gen_input + delay_line_outs[1]))\n",
    "\n",
    "        out_samples[onset_sample + i] += sum(delay_line_outs) * gain\n",
    "\n",
    "    return out_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "synthesized_d4 = string_loop_with_detuning(frequency=note2freq('D4'))\n",
    "Audio(synthesized_d4, rate=soundboard_player.fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read as read_wav\n",
    "fs_d4, d4 = read_wav('D4.wav')\n",
    "Audio(d4, rate=fs_d4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "notes_with_varying_freq = [\n",
    "    Audio(string_loop_with_detuning(frequency=frequency),\n",
    "          rate=soundboard_player.fs)\n",
    "    for frequency in notes2freqs(['A2', 'A4', 'A6'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "notes_with_varying_freq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "notes_with_varying_freq[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "notes_with_varying_freq[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Strike Position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The position of the hammer strike along the length of the string is modelled as a simple comb filter. The physically-motivated idea is that strike position can be approximately modelled as a simple delay in one of the travelling wave components. (Think about the hammer sending energy down the string to the bridge. Since energy is transferred from the hammer into the string roughly symmetrically in both directions, there is another travelling componenet that bounces off the other string termination, the agraffe, with virtually no filtering, and later arrives at the bridge.)\n",
    "\n",
    "First, we'll hear the effect of varying the \"strike position\" explicitly with the same frequency. Then we'll hear the effects of a simple method to calculate the strike position based on the frequency, based on measurements of a real piano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "varying_strike_positions = [\n",
    "    Audio(string_loop_with_detuning(strike_position=strike_position,\n",
    "                                    frequency=note2freq('D4')),\n",
    "          rate=soundboard_player.fs) for strike_position in np.linspace(1/20, 1/2, 2)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Striking near end of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "varying_strike_positions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Striking near middle of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "varying_strike_positions[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Strike Position\n",
    "## Calculate from frequency - based on real piano measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Striking positions range from 0.122 (A0) to 0.115 (A4) to 0.08 (C8)\n",
    "# Harold A. Conklin, Jr.\n",
    "# \"Design and tone in the mechanoacoustic piano. Part I. Piano hammers\n",
    "# and tonal effects\" Journal of the Acoustical Society of America\n",
    "# Vol. 99, No. 6, June 1996, p. 3293\n",
    "a4_frequency = 440.0\n",
    "def strike_position(frequency):\n",
    "    if frequency <= a4_frequency:\n",
    "        strike_scalar = (np.log10(frequency) - np.log10(lowest_frequency)) / (np.log10(a4_frequency) - np.log10(lowest_frequency))\n",
    "        return 0.122 - strike_scalar * (0.122 - 0.115)\n",
    "    else:\n",
    "        strike_scalar = (highest_frequency - frequency) / (highest_frequency - a4_frequency)\n",
    "        return 0.08 + strike_scalar * (0.115 - 0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_strike_position_by_frequency():\n",
    "    frequencies = np.linspace(lowest_frequency, highest_frequency, 200)\n",
    "    plt.figure(figsize=(16, 4))\n",
    "    strike_positions = [strike_position(frequency) for frequency in frequencies]\n",
    "    plt.plot(frequencies, strike_positions, linewidth=3, label='Strike Position')\n",
    "    plt.hlines(0.115, xmin=lowest_frequency, xmax=highest_frequency, linestyle='--', alpha=0.5)\n",
    "    plt.vlines([a4_frequency], ymin=0, ymax=1, label='$A4=0.115$')\n",
    "    plt.title('Strike Position by Frequency, Ranging from $A0$ to $C8$', size=16)\n",
    "    plt.xlim(frequencies[0], frequencies[-1])\n",
    "    plt.ylim(min(strike_positions), max(strike_positions))\n",
    "    plt.xticks(np.linspace(frequencies[0], frequencies[-1], 10))\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.legend()\n",
    "    _ = plt.ylabel('Strike position (ratio of string length)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plot_strike_position_by_frequency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "d4_frequency = note2freq('D4')\n",
    "synthesized_d4 = string_loop_with_detuning(frequency=d4_frequency,\n",
    "                                           strike_position=strike_position(d4_frequency))\n",
    "Audio(synthesized_d4, rate=soundboard_player.fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Modelling the hammer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Since the hammer acts as a nonlinear spring, the shape and time duration of the pulse varies with amplitude. A soft hit produces a wider pulse, whereas a strong hit produces a taller, narrow pulse. The duration of the pulse is also dependent on the hammer mass, so that lighter hammers used in the high registers have a shorter contact duration with the string and heavier hammers used in the lower registers have a longer contact time. The contact durations are approximately $0.5$ (ff) to $1.2$ (pp) ms at higher registers and $2.0$ (ff) to $4.0$ (pp) ms at lower registers. The frequency of the piano note determines the range of durations for the force pulse, and the amplitude value is used to linearly interpolate over this range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Anders Askenfelt and Erik Janson \"From touch to string vibrations\"\n",
    "# Five Lectures on the Acoustics of the Piano\n",
    "# http://www.speech.kth.se/music/5_lectures/askenflt/askenflt.html\n",
    "def hammer_pulse_and_gain(frequency, amplitude):\n",
    "    # All in ms units:\n",
    "    min_duration_hf = 0.5 # ff; min duration at high register\n",
    "    min_duration_lf = 2.0 # ff; min duration at low register\n",
    "    max_duration_hf = 1.2 # pp; max duration at high register\n",
    "    max_duration_lf = 4.0 # pp; max duration at low register\n",
    "    velocity_scalar = amplitude\n",
    "\n",
    "    frequency_scalar = 0.0\n",
    "    if frequency < lowest_frequency:\n",
    "        frequency_scalar = 0.0\n",
    "    elif frequency > highest_frequency:\n",
    "        frequency_scalar = 1.0\n",
    "    else:\n",
    "        frequency_scalar = (np.log10(frequency) - np.log10(lowest_frequency)) / (np.log10(highest_frequency) - np.log10(lowest_frequency))\n",
    "\n",
    "    min_duration = min_duration_lf - frequency_scalar * (min_duration_lf - min_duration_hf)\n",
    "    max_duration = max_duration_lf - frequency_scalar * (max_duration_lf - max_duration_hf)\n",
    "    pulse_duration = max_duration - velocity_scalar * (max_duration - min_duration)\n",
    "    pulse_duration *= 0.5 # My addition - less LP filtering by shrinking every pulsee\n",
    "    pulse_length = int(pulse_duration * sample_rate / 1000)\n",
    "    # pulse_length = pulse_length // 2 TODO try this again\n",
    "    pulse = 0.5 + 0.5 * np.cos(2 * np.pi * np.linspace(-0.5, 0.5, pulse_length))\n",
    "\n",
    "    return pulse, amplitude / pulse.sum() # normalize so gain is 0 dB at DC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_hammer_pulses_and_gains(frequencies_and_amplitudes, title=''):\n",
    "    colors = pl.cm.inferno(np.linspace(0,0.7,len(frequencies_and_amplitudes)))\n",
    "    pulses_and_gains = [hammer_pulse_and_gain(frequency, amplitude)\n",
    "                        for (frequency, amplitude) in frequencies_and_amplitudes]\n",
    "    max_pulse_samples = max(pulse_and_gain[0].size for pulse_and_gain in pulses_and_gains)\n",
    "    pulse_time_ms = np.linspace((-max_pulse_samples / sample_rate) / 2, (max_pulse_samples / sample_rate) / 2, max_pulse_samples) * 1000\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, pulse_and_gain in enumerate(pulses_and_gains):\n",
    "        pulse = pulse_and_gain[0]\n",
    "        gain = pulse_and_gain[1]\n",
    "        centered_pulse = np.full(max_pulse_samples, np.nan)\n",
    "        centered_pulse[:pulse.size] = pulse\n",
    "        centered_pulse = np.roll(centered_pulse, (max_pulse_samples - pulse.size) // 2)\n",
    "        plt.plot(pulse_time_ms, centered_pulse * gain, label='%0.2f Hz, Amp=%0.2f' %\n",
    "                 frequencies_and_amplitudes[i], color=colors[i], linewidth=3)\n",
    "    plt.title(title, size=16)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.xlabel('Time (ms)')\n",
    "    _ = plt.ylabel('Filter coefficient gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "frequencies_and_amplitudes = [(frequency_for_note_label(note_label), 0.9) for note_label in ['A1', 'C3', 'D4', 'G6']]\n",
    "plot_hammer_pulses_and_gains(frequencies_and_amplitudes, title='Hammer Pulses for Varying String Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "frequencies_and_amplitudes = [(frequency_for_note_label('A1'), amplitude) for amplitude in np.linspace(0.1, 1, 5)]\n",
    "plot_hammer_pulses_and_gains(frequencies_and_amplitudes, title='Hammer Pulses for Varying Strike Force')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.signal import convolve\n",
    "\n",
    "class HammerAndSoundboardExciter:\n",
    "    def __init__(self, frequency=note2freq('A1'), amplitude=1.0):\n",
    "        pulse, gain = hammer_pulse_and_gain(frequency, amplitude)\n",
    "        # The STK implementation uses an all-zero filter for the pulse,\n",
    "        # which can have a ton of coefficients (length of pulse).\n",
    "        # Simply convolving them in the time-domain once, ahead of time, is _way_ faster.\n",
    "        convolved = convolve(pulse * gain, soundboard_player_exp.samples)\n",
    "        self.combined_player = SamplePlayer(convolved)\n",
    "#         self.hammer_pulse = IirFilter()\n",
    "#         self.hammer_pulse.set_b_coefficients(pulse)\n",
    "#         self.hammer_pulse.set_gain(gain)\n",
    "    \n",
    "    def tick(self):\n",
    "        return self.combined_player.tick()\n",
    "\n",
    "    def reset(self):\n",
    "        # TODO set new freq and amp\n",
    "        self.combined_player.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Synthetic:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "hammer_and_soundboard_exciter = HammerAndSoundboardExciter(frequency=d4_frequency)\n",
    "synthetic_d4 = string_loop_with_detuning(exciter=hammer_and_soundboard_exciter,\n",
    "                                         frequency=d4_frequency,\n",
    "                                         brightness=0.8,\n",
    "                                         strike_position=strike_position(d4_frequency))\n",
    "Audio(synthetic_d4, rate=soundboard_player.fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Real:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Audio(d4, rate=fs_d4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dispersion Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Based on Faust implementation:\n",
    "# https://github.com/grame-cncm/faustlibraries/blob/master/misceffects.lib#L193-L247\n",
    "#\n",
    "# \"Dispersion Modeling in Waveguide Piano Synthesis Using Tunable\n",
    "# Allpass Filters\", by Jukka Rauhala and Vesa Valimaki, DAFX-2006, pp. 71-76\n",
    "# <http://www.dafx.ca/proceedings/papers/p_071.pdf>\n",
    "# is corrected in Dr. Rauhala's encompassing dissertation (and below).)\n",
    "# <http://www.acoustics.hut.fi/research/asp/piano/>\n",
    "def piano_dispersion_filter(f0, M=8, B=0.0001):\n",
    "    # This is a black-box to me. See links above.\n",
    "    wT = 2*np.pi*f0/fs\n",
    "    Bc = max(B, 0.000001)\n",
    "    k1 = -0.00179; k2 = -0.0233; k3 = -2.93\n",
    "    kd = np.exp(k1*np.log(Bc)*np.log(Bc) + k2*np.log(Bc) + k3)\n",
    "    m1 = 0.0126; m2 = 0.0606; m3 = -0.00825; m4 = 1.97\n",
    "    Cd = np.exp((m1*np.log(M)+m2)*np.log(Bc)+m3*np.log(M)+m4)\n",
    "    trt = 2**(1.0/12.0)\n",
    "    Ikey = np.log(f0*trt/27.5)/np.log(trt)\n",
    "    D = np.exp(Cd - Ikey*kd)\n",
    "    a1 = (1 - D)/(1 + D) # D >= 0, so a1 >= 0\n",
    "\n",
    "    polydel = lambda a: np.arctan(np.sin(wT)/(a + np.cos(wT)))/wT\n",
    "    Df0 = polydel(a1) - polydel(1.0/a1)\n",
    "\n",
    "    return FilterChain([PoleZeroFilter(a1, 1, a1) for i in range(M)]), -Df0*M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from PlotUtils import plot_frequency_response\n",
    "from ipython_animation import create_animation, DEFAULT_FPS\n",
    "\n",
    "def create_dispersion_filter_animation(animation_length_seconds=1.5, fps=DEFAULT_FPS):\n",
    "    fig, [frequency_plot, phase_plot] = plt.subplots(2, 1, figsize=(10, 6))\n",
    "\n",
    "    num_frames = fps * animation_length_seconds\n",
    "\n",
    "    min_frequency, max_frequency = note2freq('C1'), note2freq('A4')\n",
    "    impulse = np.concatenate([[1.0], np.zeros(511)])\n",
    "\n",
    "    def animate(frame):\n",
    "        frequency = min_frequency + (max_frequency - min_frequency) * frame / (num_frames - 1)\n",
    "        dispersion_filter, max_delay_samples = piano_dispersion_filter(frequency)\n",
    "\n",
    "        h = [dispersion_filter.tick(sample) for sample in impulse]\n",
    "        H = np.fft.rfft(h)\n",
    "        w = np.linspace(0, np.pi, H.size)\n",
    "        frequency_plot.cla()\n",
    "        phase_plot.cla()\n",
    "        plot_frequency_response(w, H, fig,\n",
    "                                frequency_plot, phase_plot,\n",
    "                                lower_db_lim=-20, phase_delay=True)\n",
    "        frequency_plot.set_title('Magnitude Response of Dispersion Filter (Allpass)', size=16)\n",
    "        phase_plot.set_title('Phase Response of Dispersion Filter, $f={%0.1f} Hz$' % frequency, size=16)\n",
    "        phase_plot.hlines([max_delay_samples], xmin=w[0], xmax=w[-1], label='Max delay samples\\n(for compensation)', linestyle='--')\n",
    "        phase_plot.set_ylim(-160, np.pi)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        _ = phase_plot.legend(loc='lower right')\n",
    "\n",
    "    return create_animation(fig, plt, animate, length_seconds=animation_length_seconds, default_mode='reflect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "create_dispersion_filter_animation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "class PianoString:\n",
    "    def __init__(self,\n",
    "                 brightness=0.9,\n",
    "                 frequency_jitter=0.001,\n",
    "                 detuning=0.9993,\n",
    "                 gain=1.0,\n",
    "                 # We'll get to dispersion filters later!\n",
    "                 # This function should take a frequency and return a\n",
    "                 # (filter, delay_compensation_samples) pair.\n",
    "                 dispersion_filter_fn=None,\n",
    "                 model_hammer=False,\n",
    "                 model_strike_position=False):\n",
    "        self.frequency = None\n",
    "        self.brightness = brightness\n",
    "        self.frequency_jitter = frequency_jitter\n",
    "        self.detuning = detuning\n",
    "        self.strike_position = strike_position\n",
    "        self.gain = gain\n",
    "        self.loop_gain_target = self.loop_gain = 1.0\n",
    "        self.dispersion_filter_fn = dispersion_filter_fn\n",
    "        delay_length = fs / lowest_frequency\n",
    "        self.delay_lines = [\n",
    "            AllpassDelay(delay_length, int(delay_length) + 1),\n",
    "            AllpassDelay(delay_length * detuning , int(delay_length * detuning) + 1)\n",
    "        ]\n",
    "        self.strike_comb_delay = AllpassDelay(delay_length, int(delay_length) + 1)\n",
    "\n",
    "        self.model_hammer = model_hammer\n",
    "        self.model_strike_position = model_strike_position\n",
    "        self.delay_line_outs = [0.0, 0.0]\n",
    "\n",
    "    def set_frequency(self, frequency):\n",
    "        if self.frequency == frequency:\n",
    "            return\n",
    "        self.frequency = frequency\n",
    "        delay_length = fs / frequency\n",
    "        # slight detuning across the entire \"string\" for realism\n",
    "        delay_length *= 1.0 + (np.random.uniform(low=-self.frequency_jitter, high=self.frequency_jitter) if self.frequency_jitter else 0)\n",
    "        \n",
    "        # minus 2 to compensate for extra filtering\n",
    "        filter_delays = [-2,-2]\n",
    "        self.dispersion_filters = None\n",
    "        if self.dispersion_filter_fn is not None:\n",
    "            self.dispersion_filters = [self.dispersion_filter_fn(frequency),\n",
    "                                       self.dispersion_filter_fn(frequency * self.detuning)]\n",
    "            for i in range(len(self.dispersion_filters)):\n",
    "                filter_delays[i] += self.dispersion_filters[i][1]\n",
    "                self.dispersion_filters[i] = self.dispersion_filters[i][0]\n",
    "\n",
    "        self.delay_lines[0].set_delay_samples(delay_length + filter_delays[0])\n",
    "        self.delay_lines[1].set_delay_samples(delay_length * self.detuning + filter_delays[1])\n",
    "\n",
    "        self.t60_initial, self.t60_sustain = initial_and_sustained_t60s(frequency,\n",
    "                                                                        max_initial_t60_sec=9.0,\n",
    "                                                                        max_sustained_t60_sec=20.0)\n",
    "        self.strike_comb_delay.set_delay_samples(strike_position(frequency) * delay_length)\n",
    "        self.update_loop_filters()\n",
    "\n",
    "    def set_brightness(self, brightness):\n",
    "        self.brightness = brightness\n",
    "        self.update_loop_filters()\n",
    "\n",
    "    def update_loop_filters(self):\n",
    "        self.loop_filters = [\n",
    "            sustain_brightness_filter(self.t60_initial, self.brightness, self.frequency),\n",
    "            sustain_brightness_filter(self.t60_sustain, self.brightness, self.frequency * self.detuning)\n",
    "        ]\n",
    "        \n",
    "    def tick(self):\n",
    "        if self.loop_gain < self.loop_gain_target:\n",
    "            self.loop_gain += 0.0001\n",
    "        elif self.loop_gain > self.loop_gain_target:\n",
    "            self.loop_gain -= 0.0001\n",
    "\n",
    "        in_sample = self.exciter.tick()\n",
    "        gen_input = in_sample\n",
    "        if self.model_strike_position:\n",
    "            gen_input -= self.strike_comb_delay.tick(in_sample)\n",
    "\n",
    "        # A hack to futher emulate a stronger attack.\n",
    "        # Note that this technically invalidates the sustain t60 value.\n",
    "        long_sustain_excite_gain = 0.6\n",
    "        gen_inputs = [gen_input, long_sustain_excite_gain * gen_input]\n",
    "\n",
    "        for i in range(len(self.delay_lines)):\n",
    "            into_loop_filter = self.delay_lines[i].tick(gen_inputs[i] + self.delay_line_outs[i])\n",
    "            back_into_delay_line = self.loop_filters[i].tick(into_loop_filter)\n",
    "            if self.dispersion_filters is not None:\n",
    "                back_into_delay_line = self.dispersion_filters[i].tick(back_into_delay_line)\n",
    "            self.delay_line_outs[i] = self.loop_gain * back_into_delay_line\n",
    "\n",
    "        return self.gain * sum(self.delay_line_outs)\n",
    "\n",
    "    def note_on(self, frequency, amplitude):\n",
    "        self.set_frequency(frequency)\n",
    "        # Re-instantiating the exciter for every new note for simplicity.\n",
    "        self.exciter = HammerAndSoundboardExciter(frequency, amplitude) if self.model_hammer else SamplePlayer(soundboard_player_exp.samples)\n",
    "        self.exciter.reset()\n",
    "        self.loop_gain_target = 1.0\n",
    "\n",
    "    # off-amplitude is not currently used\n",
    "    def note_off(self, amplitude=1.0):\n",
    "        # Damping coefficients range from 0.75 (A0) to 0.9 (A5 and above)\n",
    "        # Julien Bensa, \"Analyse et Synthese de sons de piano par modeles\n",
    "        # physiques et de signaux\", These de doctorat de l'universite de la\n",
    "        # Mediterranee Aix-Marseille II, 2003, p. 140\n",
    "        a5_frequency = note2freq('A5')\n",
    "        if self.frequency <= a5_frequency:\n",
    "            loop_scalar = (self.frequency - lowest_frequency) / (a5_frequency - lowest_frequency)\n",
    "            self.loop_gain_target = 0.75 + loop_scalar * (0.9 - 0.75)\n",
    "        else:\n",
    "            self.loop_gain_target = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# create a bank of strings to reuse over all examples\n",
    "piano_strings = [PianoString() for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def arpeggiate(frequencies, onset_samples,\n",
    "               brightness=0.9, model_hammer=True, model_strike_position=True,\n",
    "               dispersion_filter_fn=None):\n",
    "\n",
    "    assert(len(frequencies) == len(onset_samples))\n",
    "    assert(len(frequencies) <= len(piano_strings))\n",
    "    out_samples[:] = 0.0\n",
    "    # \"play\" lower notes more quietly for a more even sound\n",
    "    amplitudes = np.interp(frequencies, [min(frequencies), max(frequencies)], [1.0, 1.0])\n",
    "    # I found that very small amplitudes in the hammer model are just way too filtered\n",
    "    # (see flat, wide pulse curves in above charts).\n",
    "    # At the same time, mixing them lower sounds more realistic to me.\n",
    "    gains = np.interp(frequencies, [min(frequencies), max(frequencies)], [0.75, 1.0])\n",
    "\n",
    "    for i in range(len(frequencies)):\n",
    "        piano_strings[i].dispersion_filter_fn = dispersion_filter_fn\n",
    "        piano_strings[i].model_hammer = model_hammer\n",
    "        piano_strings[i].model_strike_position = model_strike_position\n",
    "        piano_strings[i].brightness = brightness\n",
    "        piano_strings[i].gain = gains[i]\n",
    "        piano_strings[i].note_on(frequencies[i], amplitudes[i])\n",
    "\n",
    "    out_samples[:] = 0.0\n",
    "    for string_i, onset_sample in enumerate(onset_samples):\n",
    "        for sample_i in range(out_samples.size - onset_sample):\n",
    "            out_samples[onset_sample + sample_i] += piano_strings[string_i].tick()\n",
    "#             if sample_i == off_sample:\n",
    "#                 piano_strings[i].note_off(1.0)\n",
    "    return out_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# three A major triads\n",
    "note_frequencies = frequencies_for_note_labels(['A2', 'C#3', 'E3',\n",
    "                                                'A4', 'C#5', 'E5',\n",
    "                                                'A5', 'C#6', 'E6'])\n",
    "onset_samples = np.logspace(np.log10(fs / 2), np.log10(fs * 4), len(note_frequencies)).astype('int')\n",
    "onset_samples -= onset_samples[0] # trigger first at sample 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### With dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "arpeggiate(note_frequencies, onset_samples,\n",
    "           brightness=0.8,\n",
    "           model_hammer=False,\n",
    "           model_strike_position=False,\n",
    "           dispersion_filter_fn=piano_dispersion_filter)\n",
    "Audio(out_samples, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Without dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "arpeggiate(note_frequencies, onset_samples,\n",
    "           brightness=0.8,\n",
    "           model_hammer=False,\n",
    "           model_strike_position=False,\n",
    "           dispersion_filter_fn=None)\n",
    "Audio(out_samples, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Modeling strike position & dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "arpeggiate(note_frequencies, onset_samples,\n",
    "           brightness=0.7,\n",
    "           model_hammer=False,\n",
    "           model_strike_position=True,\n",
    "           dispersion_filter_fn=piano_dispersion_filter)\n",
    "Audio(out_samples, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Modeling strike position, hammer pulse and dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "arpeggiate(note_frequencies, onset_samples,\n",
    "           brightness=0.98,\n",
    "           model_hammer=True,\n",
    "           model_strike_position=True,\n",
    "           dispersion_filter_fn=piano_dispersion_filter)\n",
    "Audio(out_samples, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "piano_string = PianoString(brightness=0.98,\n",
    "                           model_hammer=True,\n",
    "                           model_strike_position=True,\n",
    "                           dispersion_filter_fn=piano_dispersion_filter)\n",
    "\n",
    "num_out_samples = fs * 10\n",
    "piano_striking_single_key = np.zeros(num_out_samples)\n",
    "# Hit key every quarter second and release after a random short duration\n",
    "note_on_samples = np.arange(0, fs * 6, fs // 4)\n",
    "note_off_samples = note_on_samples + np.random.randint(low=fs//30, high=fs//6, size=note_on_samples.size)\n",
    "# \"hold down\" last note until a second before the end\n",
    "note_off_samples[-1] = num_out_samples - fs\n",
    "\n",
    "for i in range(num_out_samples):\n",
    "    if i in note_on_samples:\n",
    "        amp = np.random.uniform(low=0.7, high=1.0) if i != note_on_samples[-1] else 1.0 # end with a loud note\n",
    "        piano_string.note_on(note2freq('A#1'), amp)\n",
    "    elif i in note_off_samples:\n",
    "        piano_string.note_off()\n",
    "\n",
    "    piano_striking_single_key[i] = piano_string.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Audio(piano_striking_single_key, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 3: Woodwinds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from Filters import OneZeroFilter\n",
    "from Generators import NoiseGenerator, SineGenerator\n",
    "from AllpassDelay import AllpassDelay\n",
    "\n",
    "sample_rate = fs = 44100\n",
    "lowest_frequency = note2freq('A0')\n",
    "highest_frequency = note2freq('C8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# This class implements a simple one breakpoint,\n",
    "# non-linear reed function, as described by\n",
    "# Smith (1986).  This function is based on a\n",
    "# memoryless non-linear spring model of the reed\n",
    "# (the reed mass is ignored) which saturates when\n",
    "# the reed collides with the mouthpiece facing.\n",
    "\n",
    "# See McIntyre, Schumacher, & Woodhouse (1983),\n",
    "# Smith (1986), Hirschman, Cook, Scavone, and\n",
    "# others for more information.\n",
    "class ReedTable:\n",
    "    def __init__(self):\n",
    "        self.offset = 0.6\n",
    "        self.slope = -0.8\n",
    "\n",
    "    def tick(self, in_sample):\n",
    "        # The input is differential pressure across the reed.\n",
    "        out_sample = self.offset + self.slope * in_sample\n",
    "\n",
    "        # If output is > 1, the reed has slammed shut and the\n",
    "        # reflection function value saturates at 1.0.\n",
    "        out_sample = min(out_sample, 1.0)\n",
    "\n",
    "        # This is nearly impossible in a physical system, but\n",
    "        # a reflection function value of -1.0 corresponds to\n",
    "        # an open end (and no discontinuity in bore profile).\n",
    "        out_sample = max(-1.0, out_sample)\n",
    "\n",
    "        return out_sample\n",
    "\n",
    "    def key_on(self):\n",
    "        self.set_target(1.0)\n",
    "\n",
    "    def key_off(self):\n",
    "        self.set_target(0.0)\n",
    "\n",
    "    def set_offset(self, offset):\n",
    "        self.offset = offset\n",
    "        \n",
    "    def set_slope(self, slope):\n",
    "        self.slope = slope\n",
    "\n",
    "class EnvelopeGenerator:\n",
    "    def __init__(self):\n",
    "        self.target = 0.0\n",
    "        self.value = 0.0\n",
    "        self.rate = 0.001\n",
    "        self.state = False\n",
    "\n",
    "    def tick(self):\n",
    "        if self.state:\n",
    "            if self.target > self.value:\n",
    "                self.value += self.rate\n",
    "                if self.value >= self.target:\n",
    "                    self.value = self.target\n",
    "                    self.state = 0\n",
    "            else:\n",
    "                self.value -= self.rate\n",
    "                if self.value <= self.target:\n",
    "                    self.value = self.target\n",
    "                    self.state = False\n",
    "        return self.value\n",
    "\n",
    "    def set_rate(self, rate):\n",
    "        self.rate = rate\n",
    "    \n",
    "    def set_target(self, target):\n",
    "        self.target = target\n",
    "        if self.value != self.target:\n",
    "            self.state = True\n",
    "\n",
    "# envelope + noise + vibrato\n",
    "class BreathPressureGenerator:\n",
    "    def __init__(self):\n",
    "        self.envelope = EnvelopeGenerator()\n",
    "        self.noise = NoiseGenerator(gain=0.2)\n",
    "        self.vibrato = SineGenerator()\n",
    "        self.vibrato.set_frequency(5.735)\n",
    "        self.vibrato.amplitude = 0.05\n",
    "        \n",
    "        self.last_envelope_out = 0.0\n",
    "        self.last_noise_out = 0.0\n",
    "        self.last_vibrato_out = 0.0\n",
    "\n",
    "    def tick(self):\n",
    "        self.last_noise_out = self.noise.tick()\n",
    "        self.last_vibrato_out = self.vibrato.tick()\n",
    "\n",
    "        self.last_envelope_out = self.envelope.tick()\n",
    "        breath_pressure = self.last_envelope_out\n",
    "        breath_pressure += breath_pressure * self.last_noise_out\n",
    "        breath_pressure += breath_pressure * self.last_vibrato_out\n",
    "\n",
    "        return breath_pressure\n",
    "\n",
    "    # Apply breath pressure to instrument with given amplitude and rate of increase.\n",
    "    def start_blowing(self, amplitude, rate):\n",
    "        assert(amplitude > 0 and rate > 0)\n",
    "\n",
    "        self.envelope.set_rate(rate)\n",
    "        self.envelope.set_target(amplitude)\n",
    "\n",
    "    # Decrease breath pressure with given rate of decrease.\n",
    "    def stop_blowing(self, rate):\n",
    "        self.envelope.set_rate(rate)\n",
    "        self.envelope.set_target(0.0)\n",
    "\n",
    "    def set_vibrato_frequency(self, vibrato_frequency):\n",
    "        self.vibrato.set_frequency(vibrato_frequency)\n",
    "\n",
    "    def set_vibrato_gain(self, vibrato_gain):\n",
    "        self.vibrato.amplitude = vibrato_gain\n",
    "    \n",
    "    def set_noise_gain(self, noise_gain):\n",
    "        self.noise.gain = noise_gain\n",
    "\n",
    "    \n",
    "class Clarinet:\n",
    "    def __init__(self):\n",
    "        self.filter = OneZeroFilter()\n",
    "        self.breath_pressure_gen = BreathPressureGenerator()\n",
    "        self.output_gain = 1.0\n",
    "\n",
    "        max_delay_samples = 0.5 * fs / lowest_frequency\n",
    "        self.delay_line = AllpassDelay(max_delay_samples, int(max_delay_samples) + 1)\n",
    "\n",
    "        self.reed_table = ReedTable()\n",
    "        self.set_reed_stiffness(0.5)\n",
    "\n",
    "        self.set_frequency(note2freq('A3'))\n",
    "        self.clear()\n",
    "\n",
    "    def tick(self):\n",
    "        self.last_breath_pressure_out = self.breath_pressure_gen.tick()\n",
    "        # Perform commuted loss filtering.\n",
    "        self.last_pressure_diff = -0.95 * self.filter.tick(self.delay_line.last_out)\n",
    "        # Calculate pressure difference of reflected and mouthpiece pressures.\n",
    "        self.last_pressure_diff -= self.last_breath_pressure_out\n",
    "        self.last_reed_table_out = self.reed_table.tick(self.last_pressure_diff)\n",
    "        # Perform non-linear scattering using pressure difference in reed function.\n",
    "        return self.output_gain * self.delay_line.tick(self.last_breath_pressure_out +\n",
    "                                                       self.last_pressure_diff*self.last_reed_table_out)\n",
    "\n",
    "    def note_on(self, frequency, amplitude):\n",
    "        self.set_frequency(frequency)\n",
    "        self.breath_pressure_gen.start_blowing(0.55 + (amplitude * 0.3), amplitude * 0.001)\n",
    "        self.output_gain = amplitude + 0.001\n",
    "\n",
    "    def note_off(self, amplitude):\n",
    "        self.breath_pressure_gen.stop_blowing(amplitude * 0.01)\n",
    "\n",
    "    def set_frequency(self, frequency):\n",
    "        # Account for filter delay and one sample \"last out\" delay.\n",
    "        delay = 0.5 * (fs / frequency) - 1.0#self.filter.phase_delay(frequency) - 1.0\n",
    "        self.delay_line.set_delay_samples(delay)\n",
    "\n",
    "    # Realtime controls\n",
    "    def set_reed_stiffness(self, reed_stiffness):\n",
    "        self.reed_table.set_slope(-0.44 + (0.26 * reed_stiffness))\n",
    "    def set_noise_gain(self, noise_gain):\n",
    "        self.breath_pressure_gen.set_noise_gain(noise_gain)\n",
    "    def set_vibrato_frequency(self, vibrato_frequency):\n",
    "        self.breath_pressure_gen.set_vibrato_frequency(vibrato_frequency)\n",
    "    def set_vibrato_gain(self, vibrato_gain):\n",
    "        self.breath_pressure_gen.set_vibrato_gain(vibrato_gain)\n",
    "\n",
    "    def clear(self):\n",
    "        self.delay_line.clear()\n",
    "        self.filter.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "t = np.arange(4 * fs) / fs\n",
    "out_samples = np.zeros(t.size)\n",
    "\n",
    "def plot_woodwind_components():\n",
    "    fig, plots = plt.subplots(7, 1, figsize=(12, 16))\n",
    "    [sine_plot, noise_plot, envelope_plot, breath_plot, pressure_diff_plot, reed_table_plot, clarinet_plot] = plots\n",
    "    \n",
    "    clarinet = Clarinet()\n",
    "    clarinet.set_reed_stiffness(0.57)\n",
    "    \n",
    "    triangle = np.concatenate([np.linspace(0, 1, t.size // 2),\n",
    "                               np.linspace(1, 0, t.size // 2)])\n",
    "    noise_gain_ramp = triangle * 0.15\n",
    "    vibrato_frequency_ramp = triangle * 5\n",
    "    vibrato_gain_ramp = triangle * 0.02\n",
    "    \n",
    "    sine_y = np.zeros(t.size)\n",
    "    noise_y = np.zeros(t.size)\n",
    "    envelope_y = np.zeros(t.size)\n",
    "    breath_y = np.zeros(t.size)\n",
    "    pressure_diff_y = np.zeros(t.size)\n",
    "    reed_table_out_samples = np.zeros(t.size)\n",
    "    \n",
    "    breath_duration_samples = int(4*t.size//5) # hold for 4/5 of the duration\n",
    "    clarinet.note_on(note2freq('F4'), 0.7)\n",
    "    \n",
    "    for i in range(t.size):\n",
    "        if i == breath_duration_samples:\n",
    "            clarinet.note_off(0.005)\n",
    "    \n",
    "        clarinet.set_vibrato_frequency(vibrato_frequency_ramp[i])\n",
    "        clarinet.set_vibrato_gain(vibrato_gain_ramp[i])\n",
    "        clarinet.set_noise_gain(noise_gain_ramp[i])\n",
    "    \n",
    "        out_samples[i] = clarinet.tick()\n",
    "    \n",
    "        sine_y[i] = clarinet.breath_pressure_gen.last_vibrato_out\n",
    "        noise_y[i] = clarinet.breath_pressure_gen.last_noise_out\n",
    "        envelope_y[i] = clarinet.breath_pressure_gen.last_envelope_out\n",
    "        breath_y[i] = clarinet.last_breath_pressure_out\n",
    "        pressure_diff_y[i] = clarinet.last_pressure_diff\n",
    "        reed_table_out_samples[i] = clarinet.last_reed_table_out\n",
    "    \n",
    "    sine_plot.plot(t, sine_y)\n",
    "    sine_plot.set_title('Vibrato with Modulated Frequency and Amplitude')\n",
    "    \n",
    "    noise_plot.plot(t, noise_y)\n",
    "    noise_plot.set_title('Noise Generator with Modulated Gain')\n",
    "    \n",
    "    envelope_plot.plot(t, envelope_y)\n",
    "    envelope_plot.set_title('Breath Pressure Envelope Generator')\n",
    "    \n",
    "    breath_plot.plot(t, breath_y)\n",
    "    breath_plot.set_title('Breath Pressure Generator with Modulated Vibrato and Noise Gain')\n",
    "    \n",
    "    pressure_diff_plot.plot(t, pressure_diff_y)\n",
    "    pressure_diff_plot.set_title('Pressure Diff (Reed Table Input)')\n",
    "    \n",
    "    reed_table_plot.plot(t, reed_table_out_samples)\n",
    "    reed_table_plot.set_title('Reed Table Output Samples')\n",
    "    \n",
    "    clarinet_plot.plot(t, out_samples)\n",
    "    clarinet_plot.set_title('Clarinet Samples')\n",
    "    \n",
    "    for plot in plots:\n",
    "        plot.set_xlim(0, t.size / fs)\n",
    "        plot.set_xlabel('$t$ (sec)')\n",
    "        plot.set_ylabel('out sample')\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plot_woodwind_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Audio(out_samples, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "clarinet = Clarinet()\n",
    "clarinet.set_reed_stiffness(0.65)\n",
    "clarinet.set_noise_gain(0.3)\n",
    "clarinet.set_vibrato_gain(0.025)\n",
    "\n",
    "out_samples = np.zeros(fs * 6)\n",
    "note_frequencies = notes2freqs(['C4', 'D4', 'E4', 'F4', 'G4', 'A4', 'B4', 'C5'])\n",
    "note_on_samples = np.arange(len(note_frequencies)) * fs // 2\n",
    "note_off_samples = note_on_samples + 4 * fs // 10\n",
    "note_off_samples[-1] = out_samples.size - fs # hold last note til a second before the end\n",
    "\n",
    "note_index = 0\n",
    "for i in range(out_samples.size):\n",
    "    if np.isin(i, note_on_samples):\n",
    "        amplitude = np.random.uniform(low=0.7, high=1.0)\n",
    "        clarinet.note_on(note_frequencies[note_index], amplitude)\n",
    "        note_index += 1\n",
    "    elif np.isin(i, note_off_samples):\n",
    "        clarinet.note_off(0.008)\n",
    "    out_samples[i] = clarinet.tick()\n",
    "\n",
    "Audio(out_samples, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
